<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bloggin on Responsible AI</title>
    <link>http://localhost:1313/</link>
    
    <language>en</language>
    <copyright>Copyright 2025, Calvin Tran</copyright>
    <lastBuildDate>Thu, 13 Mar 2025 19:14:57 +0530</lastBuildDate>
    <generator>Hugo - gohugo.io</generator>
    <docs>http://cyber.harvard.edu/rss/rss.html</docs>
    <atom:link href="http://localhost:1313//atom.xml" rel="self" type="application/atom+xml"/>
    
    
    <description>Recent content on Bloggin on Responsible AI</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 15 Mar 2025 17:27:56 +0100</lastBuildDate>
    <atom:link href="http://localhost:1313/atom.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Fairness in Social Influence Maximization via Optimal Transport</title>
      <link>http://localhost:1313/posts/fairness-in-social-influence-maximization-via-optimal-transport/</link>
      <pubDate>Sat, 15 Mar 2025 17:27:56 +0100</pubDate>
      <guid>http://localhost:1313/posts/fairness-in-social-influence-maximization-via-optimal-transport/</guid>
      <description>&lt;h3 id=&#34;authors-guillaume-marin-bertin--jaishan-burton-elmo&#34;&gt;Authors: Guillaume MARIN-BERTIN &amp;amp; Jaishan BURTON ELMO&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#mutual-fairness&#34;&gt;2. Mutual Fairness: A New Metric&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#why-make-a-new-metric&#34;&gt;2.1 Why Make a New Metric?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#proposed-fairness-metric&#34;&gt;2.2 Proposed Fairness Metric&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#short-example&#34;&gt;2.3 Short Example&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#fairness-evaluation&#34;&gt;3. Metric in Practice&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#mutual-fairness-practice&#34;&gt;3.1 Mutual Fairness in Practice&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#impact-of-beta&#34;&gt;3.2 Impact of β&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#s3d-algorithm&#34;&gt;4. Improving Fairness with S3D&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#stochastic-seed-selection-descent&#34;&gt;4.1 Stochastic Seed Selection Descent (S3D)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#experimentation&#34;&gt;4.2 Experimentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#impact-of-s3d&#34;&gt;4.3 Impact of S3D&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;5. Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the article “Fairness in Social Influence Maximization via Optimal Transport” published by Shubham Chowdhary et al. in 2024 and available &lt;a href=&#34;https://neurips.cc/virtual/2024/poster/94521&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Knowledge Distillation:  Boosting Interpretability in Deep Learning Models</title>
      <link>http://localhost:1313/posts/impact-knowledge-distillation-model-interpretability/</link>
      <pubDate>Sat, 15 Mar 2025 12:16:21 +0100</pubDate>
      <guid>http://localhost:1313/posts/impact-knowledge-distillation-model-interpretability/</guid>
      <description>&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;   code.has-jax {font:inherit;&#xD;&#xA;                  font-size:100%;&#xD;&#xA;                  background: inherit;&#xD;&#xA;                  border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script TYPE=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;   MathJax.Hub.Config({&#xD;&#xA;      tex2jax: {&#xD;&#xA;         inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\$&#39;,&#39;\$&#39;]],&#xD;&#xA;         skipTags: [&#39;script&#39;,&#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;      }&#xD;&#xA;   });&#xD;&#xA;&#xD;&#xA;   MathJax.Hub.Queue(function() {&#xD;&#xA;      var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;      for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;         all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;      }&#xD;&#xA;   });&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script TYPE=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;!DOCTYPE html&gt;&#xD;&#xA;&lt;html lang=&#34;fr&#34;&gt;&#xD;&#xA;&lt;head&gt;&#xD;&#xA;   &lt;meta charset=&#34;UTF-8&#34;&gt;&#xD;&#xA;   &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;&#xD;&#xA;&lt;/head&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 28px;&#34;&gt;Interpretability, the hidden power of knowledge distillation&lt;/h1&gt;&#xD;&#xA;&lt;p&gt;Published March 15, 2025&lt;/p&gt;&#xD;&#xA;&lt;div&gt;&#xD;&#xA;  &lt;a href=&#34;https://github.com/BryanBradfo/responsible-ai-datascience-ipParis.github.io&#34; class=&#34;btn&#34; style=&#34;text-decoration: none; display: inline-block; padding: 8px 16px; background-color: #f1f1f1; border: 1px solid #ddd; border-radius: 4px; color: black;&#34;&gt;Update on GitHub&lt;/a&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;div style=&#34;display: flex; margin-top: 20px;&#34;&gt;&#xD;&#xA;   &lt;div style=&#34;display: flex; align-items: center; margin-right: 20px;&#34;&gt;&#xD;&#xA;      &lt;img src=&#34;./images/Bryan_Remi/bryan.jpeg&#34; alt=&#34;Bryan Chen&#34; style=&#34;width: 40px; height: 40px; border-radius: 50%; margin-right: 10px;&#34;&gt;&#xD;&#xA;      &lt;div&gt;&#xD;&#xA;         &lt;a href=&#34;https://github.com/BryanBradfo&#34; style=&#34;text-decoration: none; color: #0366d6;&#34;&gt;bryanbradfo&lt;/a&gt;&#xD;&#xA;         &lt;p style=&#34;margin: 0;&#34;&gt;Bryan Chen&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Visual Feature Reliance Through the Lens of Complexity</title>
      <link>http://localhost:1313/posts/understanding_visual_feature_reliance_through_the_lens_of_complexity/</link>
      <pubDate>Wed, 12 Mar 2025 16:28:12 +0100</pubDate>
      <guid>http://localhost:1313/posts/understanding_visual_feature_reliance_through_the_lens_of_complexity/</guid>
      <description>&lt;hr&gt;&lt;/hr&gt;&#xD;&#xA;&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;    tex2jax: {&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\$&#39;,&#39;\$&#39;]],&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;]&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Understanding Visual Feature Reliance through the Lens of Complexity&lt;/h1&gt;&#xD;&#xA;&lt;p&gt;&lt;strong&gt;Authors: DIB Caren, SABA Jean Paul, WANG Romain&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Article: &lt;a href=&#34;https://proceedings.neurips.cc/paper_files/paper/2024/file/819977c0a95458911bbfd9e5b5115018-Paper-Conference.pdf&#34;&gt;Understanding Visual Feature Reliance through the Lens of Complexity&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#feature-extraction&#34;&gt;Feature Extraction via Dictionary Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#detecting-complexity&#34;&gt;Detecting Complexity&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#redundancy&#34;&gt;Relations with Redundancy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#robustness&#34;&gt;Relations with Robustness&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#importance&#34;&gt;Importance Measure&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#replication&#34;&gt;Feature Flow and Information Theory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#experiment&#34;&gt;Experiment Summary: Exploring Feature Complexity in ResNet18&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#experiment_1&#34;&gt;How the Code Was Structured and What Was Done&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#experiment_2&#34;&gt;Experiment Results and Interpretation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;introduction&#34;&gt;1. Introduction&lt;/h1&gt;&#xA;&lt;p&gt;In this blog, we’ll take a deep dive into an insightful and thought-provoking paper authored by Thomas Fel, Louis Béthune, Andrew Kyle Lampinen, Thomas Serre, and Katherine Hermann. Their work explores the intricate mechanisms underlying how deep neural networks—specifically ResNet50—learn and represent complex features. This research, rooted in both theoretical and empirical analysis, investigates the nature of feature complexity, how features evolve over the course of training, and the computational structures that enable neural networks to generalize effectively.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Get a calibrated and efficient model with tailored data augmentation.</title>
      <link>http://localhost:1313/posts/mixupdatacalibration/</link>
      <pubDate>Sun, 09 Mar 2025 21:03:13 +0100</pubDate>
      <guid>http://localhost:1313/posts/mixupdatacalibration/</guid>
      <description>&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;    tex2jax: {&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;        displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h2 id=&#34;authors--tristan-waddington-fabien-lagnieu--dimitri-henrard-iratchet&#34;&gt;Authors : &lt;em&gt;Tristan Waddington, Fabien Lagnieu &amp;amp; Dimitri Henrard-Iratchet&lt;/em&gt;&lt;/h2&gt;&#xA;&lt;h2 id=&#34;comment-on-the-research-paper-tailoring-mixup-to-data-for-calibrationhttpsarxivorgabs231101434-written-by-quentin-bouniot-pavlo-mozharovskyi--florence-dalché-buc-from-ltci-télécom-paris-institut-polytechnique-de-paris-france&#34;&gt;Comment on the research paper: &lt;a href=&#34;https://arxiv.org/abs/2311.01434&#34;&gt;&lt;strong&gt;Tailoring Mixup to Data for Calibration&lt;/strong&gt;&lt;/a&gt;, written by &lt;em&gt;Quentin Bouniot, Pavlo Mozharovskyi &amp;amp; Florence d’Alché-Buc&lt;/em&gt;, from LTCI, Télécom Paris, Institut Polytechnique de Paris, France&lt;/h2&gt;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of contents&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#1-existing-data-augmentation-methods&#34;&gt;Existing Data Augmentation Methods&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#2-understanding-calibration&#34;&gt;Understanding Calibration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#3-best-of-both-worlds-tailoring-mixup-to-data-for-calibration&#34;&gt;Best of both worlds: Tailoring Mixup to Data for Calibration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&amp;ldquo;But it works well on the training set!&amp;rdquo; is the machine learning equivalent to the classic &amp;ldquo;But it works on my computer!&amp;rdquo;&lt;/p&gt;</description>
    </item>
    <item>
      <title>BitFit: BIas-Term FIne-Tuning</title>
      <link>http://localhost:1313/posts/bitfit/</link>
      <pubDate>Wed, 19 Feb 2025 15:20:48 +0100</pubDate>
      <guid>http://localhost:1313/posts/bitfit/</guid>
      <description>&lt;style&#xD;&#xA;TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;&#xD;&#xA;code.has-jax {font:&#xD;&#xA;inherit;&#xD;&#xA;font-size:&#xD;&#xA;100%; &#xD;&#xA;background: &#xD;&#xA;inherit; &#xD;&#xA;border: &#xD;&#xA;inherit;}&#xD;&#xA;&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;BitFit: A Simpler and More Efficient Approach to Fine-tuning Transformers&lt;/h1&gt;&#xD;&#xA;&lt;h3 id=&#34;authors--abdoul-r-zeba-nour-yahya-nourelhouda-klich&#34;&gt;Authors : Abdoul R. Zeba, Nour Yahya, Nourelhouda Klich&lt;/h3&gt;&#xA;&lt;h2 style=&#34;font-size: 20px;&#34;&gt; 1. Introduction &lt;/h2&gt;&#xD;&#xA;&lt;p&gt;Fine-tuning large transformer models like BERT has become the gold standard for adapting them to specific tasks. However, this process is often computationally expensive, requiring vast amounts of memory, making it impractical for many real-world applications. What if there was a way to adapt these models with minimal computational overhead while maintaining competitive performance?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Unraveling the Mysteries of Language Models: The Power of Edge Pruning in Finding Transformer Circuits</title>
      <link>http://localhost:1313/posts/edge-pruning/</link>
      <description>&lt;style
TYPE=&#34;text/css&#34;&gt;

code.has-jax {font:
inherit;
font-size:
100%; 
background: 
inherit; 
border: 
inherit;}

&lt;/style&gt;
&lt;script
type=&#34;text/x-mathjax-config&#34;&gt;

MathJax.Hub.Config({

    tex2jax: {

        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],

        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry

    }

});

MathJax.Hub.Queue(function() {

    var all = MathJax.Hub.getAllJax(), i;

    for(i = 0; i &lt; all.length; i += 1) {

        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;

    }

});

&lt;/script&gt;
&lt;script
type=&#34;text/javascript&#34;
src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;
&lt;!DOCTYPE html&gt;
&lt;html lang=&#34;en&#34;&gt;
&lt;head&gt;
&lt;meta charset=&#34;UTF-8&#34;&gt;
&lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;
&lt;title&gt;Styled Table&lt;/title&gt;
&lt;style&gt;
    table {
        border-collapse: collapse;
        width: 100%;
    }
    th, td {
        padding: 8px;
        text-align: center;
        border-bottom: 1px solid #ddd;
    }
    th {
        background-color: #f2f2f2;
    }
    tr:hover {
        background-color: #f5f5f5;
    }
&lt;/style&gt;
&lt;/head&gt;
&lt;/html&gt;
&lt;h1 style=&#34;font-size: 25px;&#34;&gt;Unraveling the Mysteries of Language Models: The Power of Edge Pruning in Finding Transformer Circuits&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Original Paper&lt;/strong&gt;: &lt;a href=&#34;https://arxiv.org/abs/2406.16778v2&#34;&gt;Finding Transformer Circuits with Edge Pruning&lt;/a&gt;&lt;/p&gt;
&lt;h1 style=&#34;font-size: 13px;&#34;&gt;Authors: Adithya Bhaskar ${ }^{1}$, Alexander Wettig ${ }$, Dan Friedman ${ }$, Danqi Chen ${ }$&lt;br&gt;${ }^{1}$ Princeton Language and Intelligence (PLI), Princeton University&lt;br&gt;adithyab@princeton.edu&lt;br&gt;{awettig, dfriedman, danqic}@cs.princeton.edu&lt;/h1&gt;
&lt;br/&gt;
&lt;p&gt;Authors of this blogpost: &lt;strong&gt;AHMED Ayan&lt;/strong&gt; &amp;amp; &lt;strong&gt;AHMED Rayyan&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;What if we told you that the technology shaping our generation is still a black box and we might know nothing about it?&lt;/p&gt;
&lt;p&gt;Language models like ChatGPT are revolutionizing the way we communicate, create, and seek information. Not only do they complete our sentences and answer our questions, but they even generate original ideas by using billions of training data—but on critical examination we should ask ourselves this one primary question, &lt;em&gt;do we truly understand how they work?&lt;/em&gt; Without looking inside these models, we risk a state of stagnation, where we rely on them without refining or improving their potential.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/BB.png&#34; alt=&#34;Black Box&#34; style=&#34;width: 400px; height: auto;&#34;&gt;
&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Fun Fact: The first two pictures of this blogpost are generated by a language model. But can you guess how it generated them?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;To push the boundaries of AI, we need a way to decode their inner workings, to see which components drive specific behaviors, and to do so with precision and efficiency.&lt;/p&gt;
&lt;p&gt;It is like trying to fine-tune an orchestra while being blindfolded. You can hear the symphony, but without seeing which instruments are playing which notes, making deliberate adjustments is nearly impossible unless you have a perfect hearing sensation(only 1% of the population has it!). Similarly, the intricate mechanisms of language models have long remained a mystery. We try to understand them effectively by making them more transparent, but so far, we have not reached there. Now, a groundbreaking technique is emerging, ready to lift the veil and transform our understanding of these powerful systems.&lt;/p&gt;
&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;section-1.1&#34;&gt;Motivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;section-1.2&#34;&gt;Existing Frameworks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;section-1.3&#34;&gt;Beyond Approximations and Greedy Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;section-1.4&#34;&gt;Scaling to Large-Scale Models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Why do we need Circuit Discovery?&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#section-2.1&#34;&gt;The Computational Graph of Transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-2.2&#34;&gt;Circuits as Subgraphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-2.3&#34;&gt;The Goal of Circuit Discovery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-2.4&#34;&gt;Previous Approaches&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Diving into the Proposed Method&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#section-3.1&#34;&gt;Why not Structured Pruning?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-3.2&#34;&gt;From Masking Nodes to Masking Edges&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-3.3&#34;&gt;Challenges and Solutions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-3.4&#34;&gt;How Do We Optimize Edge Pruning?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-3.5&#34;&gt;Edge Pruning Process-From Text to Math!&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#section-3.5.1&#34;&gt;Handling the Masks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-3.5.2&#34;&gt;Lagrangian Term&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-3.5.3&#34;&gt;Not 1 Mask but 2!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Experiments&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#section-4.1&#34;&gt;Tasks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-4.2&#34;&gt;Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Results&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Case Study: Scaling to 13B Parameters&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#section-6.1&#34;&gt;Why Scale to Larger Models?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-6.2&#34;&gt;Task and Model Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-6.3&#34;&gt;Can Edge Pruning find edge-sparse circuits in a 13B model?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-6.4&#34;&gt;To what extent do the circuits for instruction and few-shot prompting share the same edges?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-6.5&#34;&gt;Does the instruction-prompted circuit perform well when used in a few-shot manner, and vice versa?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-7&#34;&gt;Reproducibility of Experiments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-8&#34;&gt;Last Few Words of Wisdom&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;section-1&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;h3 id=&#34;section-1.1&#34;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;To tackle the aforementioned issue, researchers have turned to the concept of &amp;ldquo;circuits&amp;rdquo;—sparse computational subgraphs that highlight key interactions within a model (the definition sounds a bit complex, but it is exactly what it sounds like). These circuits serve as pathways through which the information flows and they offer a structured way to analyze which components are responsible for particular behaviors.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Think of it like the electrical wiring in your home. Every switch, bulb, and appliance is connected through a network of wires, but understanding which wire controls what can be a tangled mess!&lt;br&gt;
The ideal scenario? A streamlined, minimal wiring system that preserves full functionality without unnecessary complexity.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/EW.png&#34; alt=&#34;Electric Board&#34; style=&#34;width: 400px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;p&gt;Similarly, when analyzing the language models, researchers aim to identify circuits that are as sparse as possible—capturing only the most essential connections while maintaining the model’s performance. However, automating this process of finding circuits still remains a challenge, and existing methods as explained further, often fail to produce circuits that are truly minimal and interpretable.&lt;/p&gt;
&lt;p&gt;The paper &lt;em&gt;&amp;ldquo;Finding Transformer Circuits with Edge Pruning&amp;rdquo;&lt;/em&gt; introduces an exquisite technique as a counter to this problem. By taking advantage of a technique called &lt;strong&gt;Edge Pruning&lt;/strong&gt;, it offers a scalable, fast and efficient approach to discover circuits, allowing researchers to peel back the layers of complexity and reveal the fundamental mechanisms of Language models at play. This advancement has keen implications for natural language processing, pushing us closer to a deeper understanding of how these models operate.&lt;/p&gt;
&lt;h2 id=&#34;in-this-blog-post-well-explore-the-details-of-this-paper-breaking-down-the-concept-of-edge-pruning-its-usage-on-some-popular-datasets-and-finally-seeing-if-this-technique-scales-well-with-model-size&#34;&gt;In this blog post, we’ll explore the details of this paper, breaking down the concept of edge pruning, its usage on some popular datasets and finally seeing if this technique scales well with model size.&lt;/h2&gt;
&lt;h3 id=&#34;section-1.2&#34;&gt;Existing Frameworks&lt;/h3&gt;
&lt;p&gt;Currently, there are two primary methods that help us automate the discovery of circuits in language models: &lt;strong&gt;ACDC&lt;/strong&gt; and &lt;strong&gt;EAP&lt;/strong&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ACDC&lt;/strong&gt; uses a greedy search algorithm, which is effective but is highly computationally expensive and struggles to scale to larger models or datasets.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EAP&lt;/strong&gt;, on the other hand, takes a shortcut by using first-order approximations, making it more efficient but at the cost of fidelity—it doesn&amp;rsquo;t fully capture the true behavior of the model.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Another important point to highlight is that these approaches majorly focused on model compression by sparsifying circuits. Their main objective was compression rather than circuit discovery, leading them to remove entire components within the model, such as attention heads or MLP layers.&lt;/p&gt;
&lt;h3 id=&#34;section-1.3&#34;&gt;Beyond Approximations and Greedy Search&lt;/h3&gt;
&lt;p&gt;This paper introduces a fresh perspective on circuit discovery by &lt;strong&gt;&amp;ldquo;recasting it as an optimization problem&amp;rdquo;&lt;/strong&gt; and solving it through &lt;em&gt;gradient-based pruning&lt;/em&gt;—a technique called &lt;strong&gt;Edge Pruning&lt;/strong&gt;. Unlike previous approaches as discussed before, Edge Pruning cuts unnecessary &lt;em&gt;connections (edges)&lt;/em&gt; between components rather than removing the components themselves, leading to a more efficient and scalable solution.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Imagine trying to simplify a complex metro system. Instead of shutting down entire stations (which could break the network), you strategically remove redundant rail connections while preserving the city&amp;rsquo;s accessibility.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In a very similar way, Edge Pruning refines the structure of a language model by isolating only the most crucial connections, ensuring that its core functionality remains intact while minimizing unnecessary complexity.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/EP.gif&#34; alt=&#34;Edge Pruning&#34; style=&#34;width: 400px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;p&gt;The authors put Edge Pruning to the test in multiple benchmarks, evaluating its ability to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Identify circuits that faithfully represent the behavior of the model.&lt;/li&gt;
&lt;li&gt;Recover known ground-truth circuits.&lt;/li&gt;
&lt;li&gt;Scale efficiently to large models and datasets.&lt;/li&gt;
&lt;li&gt;Discover extremely &lt;em&gt;sparse&lt;/em&gt; circuits in massive language models.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;the-results-are-compellingedge-pruning-consistently-outperforms-prior-methods-in-both-speed-and-performance-for-example-in-the-multi-template-ioi-task-it-identifies-circuits-with-as-much-as-265-fewer-edges-than-the-next-best-method-while-maintaining-the-same-level-of-accuracy-in-predicting-model-outputs&#34;&gt;The results are compelling—Edge Pruning consistently outperforms prior methods in both speed and performance. For example, in the &lt;em&gt;multi-template IOI task&lt;/em&gt;, it identifies circuits with as much as &lt;em&gt;2.65× fewer edges&lt;/em&gt; than the next-best method while maintaining the same level of accuracy in predicting model outputs.&lt;/h2&gt;
&lt;h3 id=&#34;section-1.4&#34;&gt;Scaling to Large-Scale Models&lt;/h3&gt;
&lt;p&gt;One of the most groundbreaking aspects of Edge Pruning is its ability to handle &lt;strong&gt;massive&lt;/strong&gt; models. The authors demonstrate this with &lt;em&gt;CodeLlama-13B&lt;/em&gt;—a model &lt;strong&gt;100× larger&lt;/strong&gt; than GPT-2 Small. In a case study inspired by the BBH benchmark, they analyze how &lt;em&gt;instruction-prompting&lt;/em&gt; and &lt;em&gt;in-context learning&lt;/em&gt; mechanisms function. Shockingly, Edge Pruning identifies circuits with just &lt;strong&gt;0.04%&lt;/strong&gt; of the model’s edges, yet these circuits still capture the model&amp;rsquo;s full performance.&lt;/p&gt;
&lt;p&gt;Moreover, their findings reveal that there are significant overlaps between the circuits driving these two learning paradigms.&lt;/p&gt;
&lt;p&gt;This breakthrough paves the way for deeper interpretability of large-scale AI models, offering a scalable and precise method to uncover the hidden logic behind their decision-making processes.&lt;/p&gt;
&lt;h1 id=&#34;section-2&#34;&gt;2. Why do we need Circuit Discovery?&lt;/h1&gt;
&lt;p&gt;Imagine a complex network of roads and highways that connect different cities and towns. Each road represents a connection between different parts of a language model, and the traffic flowing through these roads represents the flow of information. The goal of circuit discovery is to identify the specific roads (or connections) that are most relevant to a particular behavior or task, such as going from Paris to Nice by road. Since we are working with Language Models whose core component is the Transformer architecture (Transformer Encoder for BERT and Decoder for ChatGPT), we will first try to understand the computational graph of Transformers.&lt;/p&gt;
&lt;h2 id=&#34;section-2.1&#34;&gt;The Computational Graph of Transformers&lt;/h2&gt;
&lt;p&gt;A Transformer is a type of neural network architecture that consists of a sequence of layers, including attention layers and MLPs (multi-layer perceptrons). These layers operate on a residual stream, which is like a highway that carries information from one layer to the next. Each layer reads the current state of the residual stream $h_i$, computes its activations $y_i$, and applies an additive update to the stream.&lt;/p&gt;
&lt;p&gt;Mathematically, this can be represented as:&lt;/p&gt;
&lt;p&gt;$$
y_i = f_i(h_i)
$$&lt;/p&gt;
&lt;p&gt;$$
h_{i+1} = h_i + y_i
$$&lt;/p&gt;
&lt;p&gt;where $y_i$ is the activation of the $i^{th}$ layer, $f_i$ is the function computed by the $i^{th}$ layer, and $h_i$ is the current state of the residual stream. The picture below shows a simple computational graph of a regular transformer.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/RTbg.png&#34; alt=&#34;Regular Transformer&#34; style=&#34;width: 300px; height: auto;&#34;&gt; 
&lt;/p&gt;
The residual stream $h_i$ can be expanded to make the dependence on prior outputs $y_{i-1}, \ldots, y_{1}$ explicit:
&lt;p&gt;$$
y_i = f_i \left( y_0 + \sum_{j=1}^{i-1} y_j \right)
$$&lt;/p&gt;
&lt;p&gt;where $y_0$ is the initialization of the residual stream with the input embeddings. But how do we form a circuit? The answer is simple! The attention heads and the MLP(s) would act as the &lt;em&gt;nodes&lt;/em&gt; of the computational subgraph whereas the connections between these layers would act as the &lt;em&gt;edges&lt;/em&gt; of the graph. For our convention, we will denote edge $j\rightarrow i$ as the connection between the output of layer $j$ to the input of layer $i$.&lt;/p&gt;
&lt;h2 id=&#34;section-2.2&#34;&gt;Circuits as Subgraphs&lt;/h2&gt;
&lt;p&gt;A circuit $\mathcal{C}$ is a subset of the computational graph $\mathcal{G}$ that isolates the specific components responsible for a particular task or behavior. Think of it like a subway system—while the full city map represents the entire model, a circuit is like a key subset of routes that efficiently connect essential stations without unnecessary detours.&lt;/p&gt;
&lt;p&gt;However, previous methods overlooked a critical factor: the impact of removing edges on the model&amp;rsquo;s performance. Simply pruning edges without considering their contribution risks breaking important pathways. The approach introduced in this paper tackles this challenge through an elegant technique called &lt;em&gt;interchange ablation&lt;/em&gt;. This method ensures that even with missing edges, the model remains functional by intelligently replacing their contributions.&lt;/p&gt;
&lt;p&gt;To illustrate, imagine a language model designed for English-to-Spanish translation. If we modify a single word in the input sentence—say, replacing “hello” with “hola”—we create a &amp;ldquo;corrupted&amp;rdquo; example. The model then processes this modified input, and the activations it generates are used to substitute the missing edges. This way, rather than simply deleting edges and hoping for the best, interchange ablation strategically fills in the gaps, allowing the model to continue producing meaningful outputs.&lt;/p&gt;
&lt;h3 id=&#34;mathematical-formulation&#34;&gt;Mathematical Formulation&lt;/h3&gt;
&lt;p&gt;For a given task, each input example $x$ is paired with a corrupted counterpart $\tilde{x}$ that alters the expected output. Following this, all corrupted outputs $\tilde{y}_j$ are computed using the modified residual stream states $\tilde{h}_j$. When an edge $j \to i$ is removed, the contribution of $y_j$ at node $i$ is substituted with its corrupted counterpart $\tilde{y}_j$.&lt;/p&gt;
&lt;p&gt;This is a game-changer—it effectively frames edge removal as a &lt;em&gt;counterfactual intervention&lt;/em&gt;, allowing researchers to analyze model behavior in a principled way. Mathematically, this process is represented as:&lt;/p&gt;
&lt;p&gt;$$
\tilde{y}_j = f_j(\tilde{h}_j)
$$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\tilde{y}_j$ is the corrupted activation at the $j^{th}$ layer,&lt;/li&gt;
&lt;li&gt;$f_j$ is the function computed by the $j^{th}$ layer,&lt;/li&gt;
&lt;li&gt;$\tilde{h}_j$ is the modified state of the residual stream.&lt;/li&gt;
&lt;/ul&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/ABLbg.png&#34; alt=&#34;Interchange Ablation&#34; style=&#34;width: 400px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;p&gt;By leveraging interchange ablation, this method provides a structured approach to pruning edges while preserving the model&amp;rsquo;s integrity, ultimately leading to more interpretable and efficient circuit discovery.&lt;/p&gt;
&lt;h2 id=&#34;section-2.3&#34;&gt;The Goal of Circuit Discovery&lt;/h2&gt;
&lt;p&gt;The goal of circuit discovery is to find a sparse subgraph (or circuit) that describes the behavior of the full model on a particular task. We want to find the minimum number of roads (or edges) that are necessary to get from the starting point to the destination. This is a challenging problem, as it involves searching through a vast space of possible circuits.&lt;/p&gt;
&lt;p&gt;Mathematically, this objective can be represented as:&lt;/p&gt;
&lt;p&gt;$$
\arg\min_{\mathcal{C}} \mathbb{E}_{(x, \tilde{x}) \in \mathcal{T}} \left[ D(p_\mathcal{G}(y|x) || p_\mathcal{C}(y|x, \tilde{x})) \right] , 1 - \frac{|\mathcal{C}|}{|\mathcal{G}|} \geq c
$$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mathcal{C}$ is the number of edges in the circuit,&lt;/li&gt;
&lt;li&gt;$\mathcal{G}$ is the number of edges in the full computational graph,&lt;/li&gt;
&lt;li&gt;$T$ is the task distribution,&lt;/li&gt;
&lt;li&gt;$p_\mathcal{G}(y|x)$ is the output of the full model,&lt;/li&gt;
&lt;li&gt;$p_\mathcal{C}(y|x, \tilde{x})$ is the output of the Transformer circuit given the original and corrupted examples $(x,\tilde{x})$,&lt;/li&gt;
&lt;li&gt;$D$ is the KL divergence between the token predictions which is simply a kind of loss,&lt;/li&gt;
&lt;li&gt;$c$ is the target sparsity.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While the above equation seems complex at first sight, it simply represents the minimum circuit $\mathcal{C}$ that can be found by minimizing the discrepancy (KL Divergence) between the output of the full model and the output of the Transformer circuit given the original and corrupted examples. The constraint here basically enforces a target sparsity of the circuit.&lt;/p&gt;
&lt;p&gt;To illustrate this further, consider a simple example of a language model that can perform addition and subtraction. The full computational graph might look like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Layer 1: Input embedding&lt;/li&gt;
&lt;li&gt;Layer 2: Attention layer 1&lt;/li&gt;
&lt;li&gt;Layer 3: Attention layer 2&lt;/li&gt;
&lt;li&gt;Layer 4: MLP layer 1&lt;/li&gt;
&lt;li&gt;Layer 5: MLP layer 2&lt;/li&gt;
&lt;li&gt;Layer 6: Output layer&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The circuit for the task of adding 2+2 might be a subset of this graph, such as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Layer 1: Input embedding&lt;/li&gt;
&lt;li&gt;Layer 3: Attention layer 2&lt;/li&gt;
&lt;li&gt;Layer 5: MLP layer 2&lt;/li&gt;
&lt;li&gt;Layer 6: Output layer&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This circuit only uses a subset of the layers and edges in the full computational graph but still produces the correct output for the input &amp;ldquo;2+2&amp;rdquo;.&lt;/p&gt;
&lt;h2 id=&#34;section-2.4&#34;&gt;Previous Approaches&lt;/h2&gt;
&lt;p&gt;Previous methods, such as ACDC, have used greedy search algorithms to solve the circuit discovery problem. At each iteration, ACDC evaluates the effect of removing each edge individually on the whole model. If the effect of removing a particular edge on the target metric is above a certain predefined threshold, it simply removes it. This algorithm has limitations, such as failing to capture the relative importance of edges and their interactions.&lt;/p&gt;
&lt;p&gt;EAP (Edge Attribution Patching), on the other hand, is a method used to assign importance scores to the edges (connections) in a Transformer model. EAP uses a linear approximation to compute the importance scores for each edge. This means that instead of calculating the exact contribution of each edge to the model&amp;rsquo;s output, EAP estimates it using a simpler, first-order method.&lt;/p&gt;
&lt;p&gt;Other methods, like those proposed by Michel et al. (2019) and Cao et al. (2021), (&lt;em&gt;structured pruning&lt;/em&gt;), focus on pruning entire attention heads or nodes instead of edges. This is like removing entire neighborhoods from our city instead of just closing certain roads.&lt;/p&gt;
&lt;h1 id=&#34;section-3&#34;&gt;3. Diving into the Proposed Method&lt;/h1&gt;
&lt;h2 id=&#34;section-3.1&#34;&gt;Why not Structured Pruning?&lt;/h2&gt;
&lt;p&gt;As discussed above, &lt;em&gt;structured pruning&lt;/em&gt; focusses on removing entire components (nodes) such as attention heads and MLP layers from the sub graph to increase the inference efficiency of the models. To decide what &lt;em&gt;nodes&lt;/em&gt; to remove and what not, a binary mask (like an on/off switch) is used. However, rather than using a strict mask that is strictly 0 and 1, researchers use a &lt;em&gt;soft&lt;/em&gt; mask that can be continuously adjusted using gradient based training. Is it effective? Yes! It has been found that structured pruning produces subgraphs with fewer nodes (components). But is it interpretable enough? No! Removing large chunks of the model makes the circuit too coarse (not detailed enough) to help understand how the model computes things.&lt;/p&gt;
&lt;h2 id=&#34;section-3.2&#34;&gt;From Masking Nodes to Masking Edges&lt;/h2&gt;
&lt;p&gt;The authors propose a way to counter that. Instead of masking nodes which might remove entire components, they mask the edges connecting them. Specifically, in this process, we freeze the weights of the original model and introduce new trainable parameters $z \in [0,1]^{|\mathcal{G}|}$. Thus, each edge in the original graph now has a trainable parameter $z_{ji}$ attached to it. Again, this trainable parameter is a &lt;em&gt;soft&lt;/em&gt; mask where $ z_{ji} = 1 $ means the edge is included and $ z_{ji} = 0 $ means the edge is removed. Does this help? Why? Yes! We are able to achieve subgraphs with greater granularity and precision when compared to structural pruning since the number of edges (connections) grows much faster (quadratically) with the number of nodes (layers).&lt;/p&gt;
&lt;p&gt;In structural pruning, if a node is removed, its activation is automatically set to 0 and it doesn&amp;rsquo;t play part in the circuit. However, for interpretability, this isn&amp;rsquo;t ideal because this changes the model too much. We obviously don&amp;rsquo;t want that! So, in edge pruning as discussed previously, we replace the activation of the removed edge not by 0 but by a corrupted activation which we refer to as &amp;ldquo;interchange activation.&amp;rdquo; This is done smoothly using a mathematical function that blends the normal activation with the corrupted one. We model the process as the masks continuously interpolating between the clean and corrupted activation. Specifically, we parameterize the i’th component as,&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;/p&gt;
$$
y_i = f_{i}\left(z_{0i}y_0 + (1 - z_{0i})\tilde{y}_0 + \sum_{1\leq j &lt; i} (z_{ji}y_j + (1 - z_{ji})\tilde{y}_j)\right)
$$
&lt;p&gt;where $ \tilde{y}_j $ represents the corrupted activations corresponding to $\tilde{x}$.&lt;/p&gt;
&lt;h2 id=&#34;section-3.3&#34;&gt;Challenges and Solutions&lt;/h2&gt;
&lt;p&gt;In a traditional model, every node receives activations from all its connected components and simply adds them up.
$$h_{i+1} = h_i + y_i$$
However, with Edge Pruning, some connections are removed, meaning each node gets a different mix of activations. Since addition assumes a fixed number of inputs, removing edges disrupts this balance, making activations harder to interpret.&lt;/p&gt;
&lt;p&gt;To solve this, we use concatenation instead of addition. This keeps activations separate, preserving their origin and making the representation clearer. Instead of a single residual stream, we introduce a disentangled residual stream, where activations $y_i$ are stored in a growing list and dynamically combined at each node’s input. This allows for more flexible and structured processing. Now, this would increase the GPU memory footprint while training, but it is essential! And, furthermore it gives results that can back it up!&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/IAbg.png&#34; alt=&#34;Disentangled Transformer&#34; style=&#34;width: 400px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;h2 id=&#34;section-3.4&#34;&gt;How Do We Optimize Edge Pruning?&lt;/h2&gt;
&lt;p&gt;To train the model with Edge Pruning, we tweak the edge weights $ z $ using &lt;strong&gt;stochastic gradient descent (SGD)&lt;/strong&gt;—basically, a trial-and-error method that gradually improves performance. The goal is to find the best set of connections that keeps the model accurate while removing unnecessary edges to make it &lt;em&gt;leaner&lt;/em&gt; and &lt;em&gt;faster&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;To enforce this sparsity, we add an $ \mathcal{L}_0 $ regularization term with a &lt;em&gt;Lagrangian penalty&lt;/em&gt;, which acts like a &amp;ldquo;cost&amp;rdquo; for keeping too many edges. This nudges the model to &amp;ldquo;drop unimportant connections&amp;rdquo; while holding on to the most useful ones.&lt;/p&gt;
&lt;p&gt;Now, here’s the tricky part: $ \mathcal{L}_0 $ is &lt;em&gt;non-differentiable&lt;/em&gt; because it simply counts how many edges are active—there&amp;rsquo;s no smooth way to calculate its slope for optimization. To get around this, we use a clever trick: instead of flipping edges on or off directly (which would be abrupt), we introduce a &lt;em&gt;smooth&lt;/em&gt; approximation called the &amp;ldquo;hard concrete&amp;rdquo; distribution (Louizos et al., 2018). This allows the model to gradually adjust edge weights, making the process trainable with standard gradient-based methods.&lt;br&gt;
At the end of training, each edge is converted into a binary &lt;em&gt;keep-or-remove&lt;/em&gt; decision based on a threshold (like 0.5), resulting in a final pruned and optimized model.&lt;/p&gt;
&lt;p&gt;The final binary mask $ M $ can be defined as:&lt;/p&gt;
&lt;p&gt;$$
M_{ji} = \mathbb{1}_{z_{ji} \geq 0.5}
$$&lt;/p&gt;
&lt;h2 id=&#34;section-3.5&#34;&gt;Edge Pruning Process-From Text to Math!&lt;/h2&gt;
&lt;h3 id=&#34;section-3.5.1&#34;&gt;Handling the Masks&lt;/h3&gt;
&lt;p&gt;Like explained before, we model the masks $z$ based on hard concrete distribution. We start by generating a random number, $u$, from a uniform distribution. This means that $u$ will be between 0 and 1, but it is distributed evenly over that range. The range is slightly adjusted by $\epsilon$ (a very small number, $10^{-6}$) to avoid edge cases of 0 and 1:
$$u\sim \mathcal{U}(\epsilon,1-\epsilon)$$
Next, we transform the value of $ u $ into another value $ s $, which determines the probability of keeping the edge. This transformation uses a sigmoid function ($ \sigma $) and a parameter $ \beta $ (which is fixed at $ \frac{2}{3} $). The sigmoid function helps smooth out the transformation to map values between 0 and 1 and $\alpha$ which is a learnable parameter, and indicates the logarithm is applied element wise:
$$
s = \sigma \left( \frac{1}{\beta} \cdot \frac{u}{1-u}+\text{log}(\alpha) \right)
$$
Now we stretch the output of the sigmoid function to fit the new range $[l,r]=[-0.1,1.1]$.
$$\tilde{s} = s \times (r - l) + l$$
Now, to get the final masks, we just accumulate the excess probability on either side by taking the minimum and maximum values to ensure that
$z$ is strictly between 0 and 1. This ensures that we either keep (1) or remove (0) the edge:
$$z = \min\left(1, \max\left(0, \tilde{s}\right)\right)$$
At the end, $ z $ will be a value between 0 and 1, representing the probability of keeping an edge.&lt;/p&gt;
&lt;h3 id=&#34;section-3.5.2&#34;&gt;Lagrangian Term&lt;/h3&gt;
&lt;p&gt;Now, we want to ensure that we prune the network to a target sparsity $t$, which is a measure of how much pruning we want to do. We introduce a Lagrangian term to penalize the model if it doesn&amp;rsquo;t meet the target sparsity $t$. The sparsity loss is calculated as:
$$\mathcal{L}_s = \lambda_1 \cdot (t - s) + \lambda_2 \cdot (t - s)^2$$
Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$s$ is the current sparsity (the proportion of edges kept).&lt;/li&gt;
&lt;li&gt;$t$ is the target sparsity (the desired proportion of edges to keep).&lt;/li&gt;
&lt;li&gt;$\lambda_1$ and $\lambda_2$ are regularization parameters that adjust how tightly the pruning should adhere to the target sparsity.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This term helps guide the pruning process and makes sure the network is pruned to a desired level without being too aggressive or too lenient. The target sparsity $t$ is not fixed but increases over time during training. It starts at a small value (e.g., 0) and gradually increases toward the desired target. This gradual increase allows the model to start with a dense network and slowly prune it over time, helping to maintain performance during early stages of training. We set the final value of $t$ to be just above 1 since we know, that $s$ would never be able to reach the target $t$ but the model will try to push $s$ towards higher sparsities.&lt;/p&gt;
&lt;h3 id=&#34;section-3.5.3&#34;&gt;Not 1 Mask but 2!&lt;/h3&gt;
&lt;p&gt;In the original setup, only edge masks were used to decide which edges to keep, but this approach led to slower pruning and lower sparsities. To speed up the process and achieve higher sparsities, node masks were introduced. Edge masks determine which edges are retained or pruned, while node masks decide whether a node remains active in the network. The interaction between node and edge masks is key: an edge $ e $ connecting two nodes $ n_1 $ and $ n_2 $ is kept if both nodes are active. This is represented as:&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;/p&gt;
$$
\tilde{z}_{(n_1, n_2)} = z_{(n_1, n_2)} \times z_{n_1}
$$
&lt;p&gt;Where $ z_{(n_1, n_2)} $ is the edge mask between nodes $ n_1 $ and $ n_2 $, and $ z_{n_1} $ is the node mask for node $ n_1 $, indicating whether the node is active. This ensures that edges are only kept if both connected nodes are active, making the pruning process more efficient.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/MEMNbg.png&#34; alt=&#34;Masks&#34; style=&#34;width: 400px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;p&gt;At the end of the pruning process, the final loss function, denoted as $ \mathcal{L}_{} $, combines multiple components to guide the pruning while ensuring the model&amp;rsquo;s performance remains intact. This total loss consists of two main parts: the KL divergence loss, $ \mathcal{L}_{KL} $, which quantifies the deviation of the pruned network from the original, and the edge sparsity loss, $ \mathcal{L}_{edge,s} $, which is simply the sum of $ \mathcal{L}_0 $ and $ \mathcal{L}_s $. Therefore, the total loss function can be expressed as:&lt;/p&gt;
&lt;p&gt;$$
\mathcal{L} = \mathcal{L}_{KL} + \mathcal{L}_{edge,s}
$$&lt;/p&gt;
&lt;h1 id=&#34;section-4&#34;&gt;4. Experiments&lt;/h1&gt;
&lt;p&gt;The experiments performed by the authors of the paper compare Edge Pruning with a Kullback-Leibler (KL) loss to the two other methods: ACDC and EAP. The choice to exclude other pruning-based methods is based on findings by Conmy et al. (2023), which indicated that these methods performed significantly worse than ACDC. All experiments are conducted using the GPT-2 Small model, which has 117 million parameters. &lt;em&gt;We could not conduct all of these experiments personally because of the high computational cost, but understanding what kind of results the authors obtained using their super powerful GPU(s), is still noteworthy&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;section-4.1&#34;&gt;Tasks&lt;/h2&gt;
&lt;p&gt;The tasks used for evaluation are designed to assess the model&amp;rsquo;s ability to identify and process indirect objects, compare numerical values, and handle gendered pronouns. The datasets are split into training, validation, and test sets to avoid overfitting artifacts. The specific tasks are as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Indirect Object Identification (IOI-t1 and IOI)&lt;/strong&gt;: This task involves sentences where the model must identify the indirect object. For example, in the sentence &lt;em&gt;&amp;ldquo;Kristi gave it to→Juana,&amp;rdquo;&lt;/em&gt; the model must recognize &lt;em&gt;&amp;ldquo;Juana&amp;rdquo;&lt;/em&gt; as the indirect object. The dataset includes 50 examples for IOI-t1 and 36,084 examples for the IOI variant.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Greater Than (GT)&lt;/strong&gt;: This task requires the model to determine the probability of a number being greater than another. For instance, given the statement &lt;em&gt;&amp;ldquo;The war lasted from the year 1743 to 17→xy,&amp;rdquo;&lt;/em&gt; the model must predict that &lt;em&gt;&amp;ldquo;xy&amp;rdquo;&lt;/em&gt; is likely to be a number greater than 43. The dataset consists of 150 training examples and 12,240 test examples.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Gendered Pronoun (GP)&lt;/strong&gt;: This task involves sentences with gendered pronouns, such as &lt;em&gt;&amp;ldquo;So Evan is a really great friend, isn’t→ he?&amp;rdquo;&lt;/em&gt; The dataset is generated using the top 1,000 most popular baby names for boys and girls, resulting in 150 training examples and 378 test examples.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tracr&lt;/strong&gt;: This task evaluates Edge Pruning on two programs compiled into Transformers: &lt;em&gt;xproportion&lt;/em&gt;, which calculates the fraction of a specific character in a sequence, and &lt;em&gt;reverse&lt;/em&gt;, which reverses a list. The performance is assessed based on how well the method recovers the ground-truth circuits.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;section-4.2&#34;&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;The faithfulness of a circuit is determined by its ability to maintain model behavior on a task when non-circuit edges are corrupted. This is evaluated using KL divergence between the model&amp;rsquo;s outputs and the circuit&amp;rsquo;s outputs. Specifically, the evaluation metrics include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For IOI-t1, IOI, and GP: The &lt;strong&gt;Logit Difference&lt;/strong&gt;:
$$
\log P(\text{correct}) - \log P(\text{misleading})
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For GT: The &lt;strong&gt;Probability Difference&lt;/strong&gt;:
$$
P(y_{y+1:99}) - P(00:y_{y-1})
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;section-5&#34;&gt;5. Results&lt;/h1&gt;
&lt;p&gt;The results of the experiments demonstrate that Edge Pruning outperforms prior methods on more complex tasks and is competitive on simpler tasks like IOI-t1 and GP.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Performance Comparison&lt;/strong&gt;: Edge Pruning consistently finds better-performing circuits across all four tasks. Specifically, on the IOI task, Edge Pruning achieves a circuit with 98.8% sparsity that is as faithful and performs as well as the one found by ACDC at 96.8% sparsity, using over 2.65 times fewer edges.&lt;/li&gt;
&lt;/ol&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/CPbg.png&#34; alt=&#34;CP&#34; style=&#34;width: 700px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Faithfulness&lt;/strong&gt;: Edge Pruning shows significantly higher faithfulness on IOI and GT compared to both ACDC and EAP, especially at higher sparsities. For instance, ACDC performs worse than random selection on IOI at high sparsities, while Edge Pruning maintains better performance.&lt;/li&gt;
&lt;/ol&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/Fbg.png&#34; alt=&#34;Faithfulness&#34; style=&#34;width: 700px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Edge Pruning scales effectively to larger datasets, such as a version of the IOI dataset with 100K examples. It demonstrates the least runtime and the highest faithfulness among the methods evaluated. In contrast, ACDC improves with more examples but suffers from prohibitive runtime, while EAP is fast but does not perform as well.&lt;/li&gt;
&lt;/ol&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/MSbg.png&#34; alt=&#34;Large Dataset&#34; style=&#34;width: 700px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Ground-Truth Circuit Recovery&lt;/strong&gt;: Edge Pruning successfully recovers the ground-truth circuits in the Tracr programs, achieving perfect reconstruction for both the &lt;em&gt;xproportion&lt;/em&gt; and &lt;em&gt;reverse&lt;/em&gt; tasks.&lt;/li&gt;
&lt;/ol&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/TRbg.png&#34; alt=&#34;Tracr&#34; style=&#34;width: 700px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;strong&gt;Robustness to Initialization&lt;/strong&gt;: The results indicate that Edge Pruning is robust to variations in random initialization. The resulting sparsity and faithfulness of the circuits found are consistent across different random initializations of masks. This consistency suggests that Edge Pruning is a reliable method for discovering circuits, regardless of the starting conditions.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;section-6&#34;&gt;6. Case Study: Scaling to 13B Parameters&lt;/h1&gt;
&lt;p&gt;In this section, we explore the scalability of Edge Pruning where the authors applied it to a much larger model, CodeLlama-13B, which had 13 billion parameters—over 100 times larger than GPT-2. This case study served two purposes: it demonstrated the effectiveness of Edge Pruning on large models and illustrated how circuit-finding methods can enhance our understanding of these complex systems.&lt;/p&gt;
&lt;h2 id=&#34;section-6.1&#34;&gt;Why Scale to Larger Models?&lt;/h2&gt;
&lt;p&gt;As AI models grow in size, understanding their inner workings becomes increasingly important. Traditional methods for interpreting these models, such as path patching and distributed alignment search, have their limitations. For instance, path patching identifies important components but does not produce edge-level circuits, while distributed alignment requires prior knowledge of the correct symbolic graph, which can be difficult to obtain.&lt;/p&gt;
&lt;p&gt;Edge Pruning, on the other hand, can efficiently scale to large models using model parallelism, making it a promising approach for interpreting multi-billion parameter models.&lt;/p&gt;
&lt;h2 id=&#34;section-6.2&#34;&gt;Task and Model Setup&lt;/h2&gt;
&lt;p&gt;The authors focus on the &lt;em&gt;Boolean Expressions&lt;/em&gt; task from the BBH benchmark suite. This task involves evaluating expressions like “((not False) and False) or (False and True) is → False.” The original dataset had only 250 examples, so they programmatically generated a larger version with 3,840 training examples, 767 validation examples, and 3,070 test examples. Each expression contains between 3 and 6 literals, with a maximum nesting depth of 3.&lt;/p&gt;
&lt;p&gt;They use the instruction-finetuned version of CodeLlama-13B, which achieves accuracies of 82% in the instruction-prompted setting and 89.25% in the few-shot setting.&lt;/p&gt;
&lt;h3 id=&#34;section-6.3&#34;&gt;Can Edge Pruning find edge-sparse circuits in a 13B model?&lt;/h3&gt;
&lt;p&gt;When we apply Edge Pruning to the task, we discover two circuits: one for instruction prompting and one for few-shot prompting. The results are impressive:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The circuit found in the instruction-prompted setting has 1,041 edges, corresponding to 99.97% edge sparsity.&lt;/li&gt;
&lt;li&gt;The circuit found in the few-shot setting has 1,464 edges, equivalent to 99.96% edge sparsity.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Despite using less than 0.04% of the edges, these circuits closely match the performance of the full model. For instance, the few-shot circuit achieves an accuracy of 87.25%, performing within 2% of the full model when prompted in a few-shot manner. The instruction-prompted circuit is accurate within 2.75% of the full model.&lt;/p&gt;
&lt;h3 id=&#34;section-6.4&#34;&gt;To what extent do the circuits for instruction and few-shot prompting share the same edges?&lt;/h3&gt;
&lt;p&gt;Next, we examine the overlap between the instruction-prompted and few-shot circuits. The two circuits share 653 edges, accounting for 62.7% of the edges in the sparser instruction-prompted circuit. This overlap is over 1,700 times larger than what would be expected by random chance.&lt;/p&gt;
&lt;p&gt;The authors evaluate the performance of the circuit formed by this intersection in both prompting settings. It performs well in the instruction-prompted setting and significantly above chance when prompted in a few-shot manner.&lt;/p&gt;
&lt;h3 id=&#34;section-6.5&#34;&gt;Does the instruction-prompted circuit perform well when used in a few-shot manner, and vice versa?&lt;/h3&gt;
&lt;p&gt;The results indicate that the circuits demonstrate strong performance when evaluated across different prompting methods. For example, the few-shot circuit performs well even when used in the instruction-prompted setting, and vice versa. This suggests that the same underlying mechanisms are at play in both prompting scenarios.&lt;/p&gt;
&lt;p&gt;However, there is still a performance gap between the circuits. For instance, the few-shot circuit achieves 87.25% accuracy when evaluated in the few-shot setting but drops to 75.75% in the instruction-prompted setting. This indicates that while there is significant overlap, additional components may be necessary to fully capture the model&amp;rsquo;s behavior.&lt;/p&gt;
&lt;p&gt;Interpreting circuits in such large models, even when sparse, remains a challenging task. The authors isolate a small region of the circuit and identify intriguing behaviors, leading to interesting conjectures. However, a thorough analysis requires more extensive study, which is an exciting avenue for future research.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/CSbg.png&#34; alt=&#34;Case Study&#34; style=&#34;width: 700px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;h1 id=&#34;section-7&#34;&gt;7. Reproducibility of Experiments&lt;/h1&gt;
&lt;p&gt;The computational budget for our experiments was limited, which presented several challenges during the reproduction process. Specifically, we attempted to replicate the results of one of the experiments on the GT dataset using the GPT-2 small model. During this process, we encountered an issue with the &lt;code&gt;requirements.txt&lt;/code&gt; file, where the specified tracr file could not be found at the provided link. As a result, we had to revise our approach and focus exclusively on the GPT-2 small experiments, omitting other components initially included in the original experimental setup.&lt;/p&gt;
&lt;p&gt;Given the constraints of our hardware—a relatively weak GPU—we encountered further difficulties in terms of memory and processing power. To mitigate these issues, we reduced the &lt;code&gt;per_device_train_batch size&lt;/code&gt; significantly, from 8 (as originally intended) to 4 and &lt;code&gt;per_device_eval_batch_size&lt;/code&gt; to 2. In addition to this adjustment, we modified other hyperparameters, including setting &lt;code&gt;NTRAIN = 10,000&lt;/code&gt; while performing the hyperparameter sweep on the GT dataset. These adjustments were essential for managing the computational limitations and were necessary to ensure that the experiment could run without hardware bottlenecks.
Here are some snippets from the code that we ran:
Run the pruning script &lt;code&gt;src/prune/fpt2_gt.py&lt;/code&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/S2.png&#34; alt=&#34;Res&#34; style=&#34;width: 700px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;p&gt;Running the hyperparameter sweep &lt;code&gt;run_scripts/gt_sweep.sh&lt;/code&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/S3W.png&#34; alt=&#34;Res1&#34; style=&#34;width: 700px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;p&gt;We faced the out of memory error. So we had to change the hyperparameters. On making the changes, we were able to run the experiment.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/R3HS.jpg&#34; alt=&#34;Res2&#34; style=&#34;width: 700px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/R4.jpg&#34; alt=&#34;Res4&#34; style=&#34;width: 700px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;p&gt;The following hyperparameters were used during training:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;learning_rate: 5e-05&lt;/li&gt;
&lt;li&gt;train_batch_size: 4&lt;/li&gt;
&lt;li&gt;eval_batch_size: 2&lt;/li&gt;
&lt;li&gt;seed: 42&lt;/li&gt;
&lt;li&gt;optimizer: Use OptimizerNames.ADAMW_TORCH with betas=(0.9,0.999) and epsilon=1e-08 and optimizer_args=No additional optimizer arguments&lt;/li&gt;
&lt;li&gt;lr_scheduler_type: linear&lt;/li&gt;
&lt;li&gt;lr_scheduler_warmup_steps: 10&lt;/li&gt;
&lt;li&gt;training_steps: 5&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While these modifications diverged from the original setup, we were able to successfully run the experiment. However, the high computational cost meant that we were unable to replicate all aspects of the original experiment with full fidelity. Future work with access to more resources would be beneficial for verifying the results under original conditions.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/R1.png&#34; alt=&#34;Case Study&#34; style=&#34;width: 700px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;p&gt;These adjustments were critical in enabling us to run the experiment, though they may have impacted the results. But we observe that the reults indicate that the algorithm is indeed trying to increase the edge sparsity which validates the fact that this algorithm is efficient. We encourage other researchers to replicate this work with higher computational resources to validate the findings further.&lt;/p&gt;
&lt;h1 id=&#34;section-8&#34;&gt;8. Last Few Words of Wisdom&lt;/h1&gt;
&lt;p&gt;We introduced &lt;strong&gt;Edge Pruning&lt;/strong&gt;, a method for discovering circuits by pruning edges between model components. The experiments demonstrate that it identifies sparse, faithful circuits while scaling effectively to large datasets and models. However, it does come with trade-offs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Limitations:&lt;/strong&gt; While Edge Pruning is highly accurate, approximation-based methods like EAP are faster for smaller datasets. Scaling to large models also demands significant GPU resources—32 H100 GPUs were used for CodeLlama-13B. A hybrid approach, combining a fast approximation method like EAP with Edge Pruning for refinement, could offer a balance between efficiency and performance. Additionally, even at extreme sparsities, circuits in large models remain complex, highlighting the need for automated interpretability tools and improved faithfulness metrics.&lt;/p&gt;
&lt;p&gt;As AI models grow in scale and complexity, methods like Edge Pruning will play a crucial role in making them more interpretable and efficient. Its ability to discover meaningful circuits while maintaining high faithfulness positions it as a valuable tool for research and real-world applications. Future work could explore refining the pruning process, identifying multiple circuits for complex tasks, and improving efficiency.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
   &lt;img src=&#34;./images/Images_Ahmed_Ahmed/aibg.png&#34; alt=&#34;AI&#34; style=&#34;width: 700px; height: auto;&#34;&gt; 
&lt;/p&gt;
&lt;p&gt;By advancing these approaches, we move towards AI systems that are not just powerful but also more &lt;em&gt;transparent, accurate, robust&lt;/em&gt; and &lt;em&gt;trustworthy&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;quiz-section&#34;&gt;Test Your Understanding&lt;/h2&gt;
&lt;p&gt;Think you grasp the key ideas? Take this short quiz to test your understanding!&lt;/p&gt;
&lt;form id=&#34;quiz-form&#34; class=&#34;quiz-form&#34;&gt;
    &lt;div class=&#34;quiz-question&#34;&gt;
        &lt;p&gt;Why is it difficult to understand how large language models work?&lt;/p&gt;
        &lt;div class=&#34;quiz-options&#34;&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question1&#34; value=&#34;1&#34;&gt;
                They are based on simple rule-based algorithms.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question1&#34; value=&#34;2&#34;&gt;
                Their inner workings are complex and not directly interpretable.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question1&#34; value=&#34;3&#34;&gt;
                They do not require training data.
            &lt;/label&gt;
        &lt;/div&gt;
        &lt;p&gt;What are &#39;circuits&#39; in the context of language models?&lt;/p&gt;
        &lt;div class=&#34;quiz-options&#34;&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question2&#34; value=&#34;1&#34;&gt;
                A method for compressing large models.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question2&#34; value=&#34;2&#34;&gt;
                Sparse computational subgraphs that highlight key interactions within a model.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question2&#34; value=&#34;3&#34;&gt;
                A way to increase the number of parameters in a model.
            &lt;/label&gt;
        &lt;/div&gt;
        &lt;p&gt;What is the main advantage of the Edge Pruning technique?&lt;/p&gt;
        &lt;div class=&#34;quiz-options&#34;&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question3&#34; value=&#34;1&#34;&gt;
                It removes entire components of the model, such as attention heads.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question3&#34; value=&#34;2&#34;&gt;
                It eliminates unnecessary connections while preserving model functionality.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question3&#34; value=&#34;3&#34;&gt;
                It makes models slower but more interpretable.
            &lt;/label&gt;
        &lt;/div&gt;
        &lt;p&gt;Why do we need Circuit Discovery?&lt;/p&gt;
        &lt;div class=&#34;quiz-options&#34;&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question4&#34; value=&#34;1&#34;&gt;
                To simplify neural networks by reducing layers.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question4&#34; value=&#34;2&#34;&gt;
                To identify the key connections responsible for specific tasks in a model.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question4&#34; value=&#34;3&#34;&gt;
                To increase the number of parameters for better performance.
            &lt;/label&gt;
        &lt;/div&gt;
        &lt;p&gt;What is the goal of Circuit Discovery?&lt;/p&gt;
        &lt;div class=&#34;quiz-options&#34;&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question5&#34; value=&#34;1&#34;&gt;
                To randomly remove connections in a model.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question5&#34; value=&#34;2&#34;&gt;
                To find the smallest possible subgraph that explains a model’s behavior on a specific task.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question5&#34; value=&#34;3&#34;&gt;
                To replace all model connections with random noise.
            &lt;/label&gt;
        &lt;/div&gt;
        &lt;p&gt;Why not use Structured Pruning for Circuit Discovery?&lt;/p&gt;
        &lt;div class=&#34;quiz-options&#34;&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question6&#34; value=&#34;1&#34;&gt;
                Structured pruning removes too many critical components, making interpretation harder.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question6&#34; value=&#34;2&#34;&gt;
                Structured pruning is always the best approach for circuit discovery.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question6&#34; value=&#34;3&#34;&gt;
                Structured pruning does not affect model performance.
            &lt;/label&gt;
        &lt;/div&gt;
        &lt;p&gt;What is the purpose of the &#34;interchange activation&#34; in edge pruning?&lt;/p&gt;
        &lt;div class=&#34;quiz-options&#34;&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question7&#34; value=&#34;1&#34;&gt;
                To replace removed edges with random noise.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question7&#34; value=&#34;2&#34;&gt;
                To preserve the model’s interpretability by replacing removed edges with a corrupted activation.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question7&#34; value=&#34;3&#34;&gt;
                To increase the number of edges in the model.
            &lt;/label&gt;
        &lt;/div&gt;
         &lt;p&gt;How does the edge pruning process address the issue of adding or removing edges in neural networks?&lt;/p&gt;
        &lt;div class=&#34;quiz-options&#34;&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question8&#34; value=&#34;1&#34;&gt;
                By using concatenation instead of addition to preserve the origin of activations.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question8&#34; value=&#34;2&#34;&gt;
                By using addition to combine activations from all edges.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question8&#34; value=&#34;3&#34;&gt;
                By replacing removed edges with zero values.
            &lt;/label&gt;
        &lt;/div&gt;
        &lt;p&gt;What is the purpose of the Lagrangian penalty in the edge pruning process?&lt;/p&gt;
        &lt;div class=&#34;quiz-options&#34;&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question9&#34; value=&#34;1&#34;&gt;
                To prevent the model from pruning any edges during training.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question9&#34; value=&#34;2&#34;&gt;
                To enforce sparsity by adding a cost for keeping too many edges.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question9&#34; value=&#34;3&#34;&gt;
                To ensure that all nodes are activated during training.
            &lt;/label&gt;
        &lt;/div&gt;
        &lt;p&gt;How does the introduction of node masks affect edge pruning?&lt;/p&gt;
        &lt;div class=&#34;quiz-options&#34;&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question10&#34; value=&#34;1&#34;&gt;
                It prevents edges from being pruned entirely.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question10&#34; value=&#34;2&#34;&gt;
                It ensures edges are kept only if both connected nodes are active, making the pruning process more efficient.
            &lt;/label&gt;
            &lt;label&gt;
                &lt;input type=&#34;radio&#34; name=&#34;question10&#34; value=&#34;3&#34;&gt;
                It makes the edge pruning process slower and more complex.
            &lt;/label&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;button type=&#34;submit&#34; class=&#34;quiz-submit&#34;&gt;Submit&lt;/button&gt;
&lt;/form&gt;
&lt;div id=&#34;quiz-results&#34; class=&#34;quiz-results&#34;&gt;&lt;/div&gt;
&lt;script&gt;
    // Define quiz questions and correct answers
    const quizQuestions = [
        {
            question: &#34;Why is it difficult to understand how large language models work?&#34;,
            answer: &#34;2&#34;
        },
        {
            question: &#34;What are &#39;circuits&#39; in the context of language models?&#34;,
            answer: &#34;2&#34;
        },
        {
            question: &#34;What is the main advantage of the Edge Pruning technique?&#34;,
            answer: &#34;2&#34;
        },
        { 
            question: &#34;Why do we need Circuit Discovery?&#34;, 
            answer: &#34;2&#34; 
        },
        { 
            question: &#34;What is the goal of Circuit Discovery?&#34;,
            answer: &#34;2&#34; 
        },
        { 
            question: &#34;Why not use Structured Pruning for Circuit Discovery?&#34;,
            answer: &#34;1&#34; 
        },
        { 
            question: &#34;What is the purpose of the &#39;interchange activation&#39; in edge pruning?&#34;,
            answer: &#34;2&#34; 
        },
        { 
            question: &#34;How does the edge pruning process address the issue of adding or removing edges in neural networks?&#34;, 
            answer: &#34;1&#34; 
        },
        { 
            question: &#34;What is the purpose of the Lagrangian penalty in the edge pruning process?&#34;, 
            answer: &#34;2&#34; 
        },
        { 
            question: &#34;How does the introduction of node masks affect edge pruning?&#34;,
            answer: &#34;2&#34; 
        }
    ];

    // Handle form submission
    document.getElementById(&#39;quiz-form&#39;).addEventListener(&#39;submit&#39;, function(event) {
        event.preventDefault();

        // Calculate quiz score
        let score = 0;
        quizQuestions.forEach(question =&gt; {
            const selectedAnswer = document.querySelector(`input[name=&#34;question${quizQuestions.indexOf(question) + 1}&#34;]:checked`);
            if (selectedAnswer) {
                if (selectedAnswer.value.toLowerCase() === question.answer) {
                    score++;
                    selectedAnswer.parentElement.classList.add(&#39;correct&#39;);
                } else {
                    selectedAnswer.parentElement.classList.add(&#39;incorrect&#39;);
                }
            }
        });

        // Display quiz results
        const quizResults = document.getElementById(&#39;quiz-results&#39;);
        quizResults.innerHTML = `&lt;p&gt;You scored ${score} out of ${quizQuestions.length}.&lt;/p&gt;`;
    });
&lt;/script&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Bhaskar, A., Wettig, A., Friedman, D., &amp;amp; Chen, D. (2024). Finding Transformer Circuits with Edge Pruning. &lt;em&gt;arXiv&lt;/em&gt;. &lt;a href=&#34;https://arxiv.org/abs/2406.16778&#34;&gt;https://arxiv.org/abs/2406.16778&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Tang, P., Xie, C. &amp;amp; Duan, H. Node and edge dual-masked self-supervised graph representation. Knowl Inf Syst 66, 2307–2326 (2024). &lt;a href=&#34;https://doi.org/10.1007/s10115-023-01950-2&#34;&gt;https://doi.org/10.1007/s10115-023-01950-2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Syed, A., Rager, C., &amp;amp; Conmy, A. (2023). Attribution Patching Outperforms Automated Circuit Discovery. &lt;em&gt;arXiv&lt;/em&gt;. &lt;a href=&#34;https://arxiv.org/abs/2310.10348&#34;&gt;https://arxiv.org/abs/2310.10348&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Conmy, A., Mavor-Parker, A. N., Lynch, A., Heimersheim, S., &amp;amp; Garriga-Alonso, A. (2023). Towards Automated Circuit Discovery for Mechanistic Interpretability. &lt;em&gt;arXiv&lt;/em&gt;. &lt;a href=&#34;https://arxiv.org/abs/2304.14997&#34;&gt;https://arxiv.org/abs/2304.14997&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;script&gt;
function highlight(text) {
  var inputText = document.getElementById(&#34;markdown-content&#34;);
  var innerHTML = inputText.innerHTML;
  var index = innerHTML.indexOf(text);
  if (index &gt;= 0) {
    innerHTML = innerHTML.substring(0, index) + &#34;&lt;span class=&#39;highlight&#39;&gt;&#34; + innerHTML.substring(index, index + text.length) + &#34;&lt;/span&gt;&#34; + innerHTML.substring(index + text.length);
    inputText.innerHTML = innerHTML;
  }
}
highlight(&#34;Unravelling Mysteries of Language Models&#34;);
&lt;/script&gt;
&lt;hr&gt;
&lt;script&gt;
    function displayInput() {
        var inputValue = document.getElementById(&#34;inputField&#34;).value;
        document.getElementById(&#34;output&#34;).innerText = &#34;You typed: &#34; + inputValue;
    }
&lt;/script&gt;
&lt;style&gt;
/* Elegant Highlighting */
.highlight {
  background-color: #f1f1f1;
  color: #333;
  padding: 0 6px;
  border-radius: 6px;
  font-weight: 500;
  box-shadow: inset 0 0 8px rgba(0, 0, 0, 0.1);
  transition: background-color 0.3s ease, transform 0.3s ease;
}

/* Hover Effect on Highlight */
.highlight:hover {
  background-color: #b3e5fc;
  transform: scale(1.05);
}

/* Elegant Quiz Form */
.quiz-form {
    max-width: 700px;  /* Increased width */
    margin: 40px auto;
    padding: 40px;
    background: #ffffff;
    border-radius: 15px;
    box-shadow: 0 15px 25px rgba(0, 0, 0, 0.1);
    font-family: &#39;Roboto&#39;, sans-serif;  /* Unified font family for questions and answers */
    transition: transform 0.3s ease, box-shadow 0.3s ease;
}

.quiz-form:hover {
    transform: translateY(-5px);
    box-shadow: 0 25px 45px rgba(0, 0, 0, 0.2);
}

/* Refined Typography for Quiz Question */
.quiz-question {
    font-size: 1.1em;  /* Reduced font size */
    margin-bottom: 20px;
    font-family: &#39;Roboto&#39;, sans-serif;  /* Unified font for both questions and answers */
    color: #444;
    line-height: 1.4;
}

/* Stylish Options */
.quiz-options label {
    display: block;
    margin-bottom: 18px;
    font-family: &#39;Roboto&#39;, sans-serif;  /* Unified font for both questions and answers */
    font-size: 1.1em;  /* Reduced font size */
    padding: 12px 18px;
    border: 2px solid #e0e0e0;
    border-radius: 10px;
    transition: all 0.3s ease;
    cursor: pointer;
    background-color: #fafafa;
    color: #555;
}

/* Option Hover Effect */
.quiz-options label:hover {
    background-color: #e0f7fa;
    border-color: #00bcd4;
    transform: translateX(3px);
}

/* Correct and Incorrect Labels */
.quiz-options label.correct {
    background-color: #81c784;
    border-color: #66bb6a;
    color: #fff;
}

.quiz-options label.incorrect {
    background-color: #f44336;
    border-color: #e53935;
    color: #fff;
}

/* Elegant Submit Button */
.quiz-submit {
    background: linear-gradient(90deg, #81c784, #4caf50);
    color: white;
    padding: 14px 28px;
    border: none;
    border-radius: 30px;
    font-size: 1.2em;
    cursor: pointer;
    transition: background 0.3s ease, transform 0.3s ease;
    font-family: &#39;Roboto&#39;, sans-serif;
}

.quiz-submit:hover {
    background: linear-gradient(90deg, #66bb6a, #388e3c);
    transform: translateY(-3px);
}

/* Results Text */
.quiz-results {
    margin-top: 25px;
    font-size: 1.2em;  /* Reduced font size */
    font-weight: bold;
    text-align: center;
    color: #4caf50;
}

.quiz-results.incorrect {
    color: #f44336;
}

/* Smooth Transitions for Hover Effects */
.quiz-form, .quiz-submit, .quiz-options label {
    transition: all 0.3s ease;
}

/* Elegant Link Hover Effect */
a[name]:hover {
    background-color: #ffeb3b;
    text-decoration: none;
    color: inherit;
    border-radius: 6px;
    padding: 2px 8px;
}
&lt;/style&gt;
</description>
      <author>Students from M2 Data Science IP Paris</author>
      <guid>http://localhost:1313/posts/edge-pruning/</guid>
      <pubDate>Thu, 13 Mar 2025 19:14:57 +0530</pubDate>
    </item>
    
    <item>
      <title>How to augment my dataset?</title>
      <link>http://localhost:1313/posts/mixupdatacalibration/</link>
      <description>&lt;style TYPE=&#34;text/css&#34;&gt;
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
&lt;/style&gt;
&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],
        displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],
        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry
    }
});
MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;
    }
});
&lt;/script&gt;
&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;
&lt;h1 id=&#34;authors--tristan-waddington-fabien-lagnieu--dimitri-henrard-iratchet&#34;&gt;Authors : &lt;em&gt;Tristan Waddington, Fabien Lagnieu &amp;amp; Dimitri Henrard-Iratchet&lt;/em&gt;&lt;/h1&gt;
&lt;h3 id=&#34;paper-comment-on-the-research-paper-tailoring-mixup-to-data-for-calibration-written-by-quentin-bouniot-pavlo-mozharovskyi--florence-dalché-buc-from-ltci-télécom-paris-institut-polytechnique-de-paris-france&#34;&gt;Paper: Comment on the research paper: &lt;a href=&#34;https://arxiv.org/abs/2311.01434&#34;&gt;&lt;strong&gt;Tailoring Mixup to Data for Calibration&lt;/strong&gt;&lt;/a&gt;, written by &lt;em&gt;Quentin Bouniot, Pavlo Mozharovskyi &amp;amp; Florence d’Alché-Buc&lt;/em&gt;, from LTCI, Télécom Paris, Institut Polytechnique de Paris, France&lt;/h3&gt;
&lt;p&gt;TODO: insert table of contents&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;img
  src=&#34;./images/MixUpDataCalibration/AI_introvert.png&#34;
  alt=&#34;Test image Mkdown&#34;
  loading=&#34;lazy&#34;
  decoding=&#34;async&#34;
  class=&#34;full-width&#34;
/&gt;


Let&amp;rsquo;s do it.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img src=&#34;./images/MixUpDataCalibration/AI_introvert.png&#34; alt=&#34;Test image mathematical&#34;&gt;
&lt;/p&gt;
&lt;h1 id=&#34;main-part&#34;&gt;Main part&lt;/h1&gt;
&lt;p&gt;Test LaTeX : $\sigma \left( \frac{1}{2}\right)$&lt;/p&gt;
&lt;p&gt;$$\mathbb{R}^3 $$&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
</description>
      <author>Students from M2 Data Science IP Paris</author>
      <guid>http://localhost:1313/posts/mixupdatacalibration/</guid>
      <pubDate>Wed, 05 Feb 2025 14:03:13 +0100</pubDate>
    </item>
    
    <item>
      <title>Axiomatic Explanations for Visual Search, Retrieval and Similarity Learning</title>
      <link>http://localhost:1313/posts/axiomatic_explanations/</link>
      <pubDate>Thu, 28 Mar 2024 05:58:39 +0100</pubDate>
      <guid>http://localhost:1313/posts/axiomatic_explanations/</guid>
      <description>&lt;style&#xD;&#xA;TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;&#xD;&#xA;code.has-jax {font:&#xD;&#xA;inherit;&#xD;&#xA;font-size:&#xD;&#xA;100%; &#xD;&#xA;background: &#xD;&#xA;inherit; &#xD;&#xA;border: &#xD;&#xA;inherit;}&#xD;&#xA;&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;!DOCTYPE html&gt;&#xD;&#xA;&lt;html lang=&#34;en&#34;&gt;&#xD;&#xA;&lt;head&gt;&#xD;&#xA;&lt;meta charset=&#34;UTF-8&#34;&gt;&#xD;&#xA;&lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;&#xD;&#xA;&lt;title&gt;Styled Table&lt;/title&gt;&#xD;&#xA;&lt;style&gt;&#xD;&#xA;    table {&#xD;&#xA;        border-collapse: collapse;&#xD;&#xA;        width: 100%;&#xD;&#xA;    }&#xD;&#xA;    th, td {&#xD;&#xA;        padding: 8px;&#xD;&#xA;        text-align: center;&#xD;&#xA;        border-bottom: 1px solid #ddd;&#xD;&#xA;    }&#xD;&#xA;    th {&#xD;&#xA;        background-color: #f2f2f2;&#xD;&#xA;    }&#xD;&#xA;    tr:hover {&#xD;&#xA;        background-color: #f5f5f5;&#xD;&#xA;    }&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;/head&gt;&#xD;&#xA;&lt;/html&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;AXIOMATIC EXPlanATIONS FOR VISUAL SEARCh, RETRIEVAL, AND SIMILARITY LEARNING &lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 13px;&#34;&gt;Authors:Mark Hamilton ${ }^{1,2}$, Scott Lundberg ${ }^{2}$, Stephanie Fu ${ }^{1}$, Lei Zhang ${ }^{2}$, William T. Freeman ${ }^{1,3}$&lt;br&gt;${ }^{1}$ MIT, ${ }^{2}$ Microsoft, ${ }^{3}$ Google&lt;br&gt;markth@mit.edu&#xD;&#xA;&lt;br/&gt;&#xD;&#xA;**Authors of the blogpost**: Yassine Beniguemim and Noureddine BOULLAM.&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0.0&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0.1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Exploring Visual Search Algorithm Explanations&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.1&#34;&gt;First-Order Explanations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.2&#34;&gt;Unifying First-Order Search Interpretation Techniques&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.3&#34;&gt;Second-Order Explanations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.4&#34;&gt;A Fast Shapley-Taylor Approximation Kernel&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.5&#34;&gt;Second-Order Search Activation Maps&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Implementing Second-Order Explanations in Practice&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0.0&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;Visual search, recommendation, and contrastive similarity learning are pivotal technologies shaping user experiences in the digital age. However, the complexity of modern model architectures often obscures their inner workings, making them challenging to interpret. In our blog, we delve into a groundbreaking paper titled &amp;ldquo;AXIOMATIC EXPLANATIONS FOR VISUAL SEARCH, RETRIEVAL, AND SIMILARITY LEARNING&amp;rdquo; authored by Mark Hamilton et al. This paper introduces a novel framework grounded in the theory of fair credit assignment, providing axiomatic solutions that generalize existing explanation techniques and address fairness concerns in recommendation systems. Through our exploration, we aim to demystify the complexities of visual search algorithms, offering readers insights into their operation and implications for various domains.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Privacy Amplification by Decentralization</title>
      <link>http://localhost:1313/posts/privacy-amplification/</link>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Privacy Amplification by Decentralization&lt;/h1&gt;
&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Author: Sarah ABBANA BENNANI &lt;/h1&gt;
&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction - the challenge of data privacy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Theoretical Aspects on Differential Privacy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;First Case: walk on a ring&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Generalisation: walk on a complete graph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Experiments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Perspectives&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br /&gt;
&lt;p&gt;This is a blogpost about the paper  Privacy Amplification by Decentralization, published by E. Cyffers et al. in 2022 and available &lt;a href=&#34;https://proceedings.mlr.press/v151/cyffers22a/cyffers22a.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;section-1&#34;&gt;&lt;h1 style=&#34;font-size: 20px;&#34;&gt;Introduction - the challenge of data privacy&lt;/h1&gt;&lt;/h1&gt;
&lt;p&gt;In recent years, the concept of privacy has gained significant attention due to the proliferation of data collection practices and the need to safeguard individuals&amp;rsquo; personal information. &lt;br&gt;
There has been a notable shift towards implementing regulations to govern the gathering of data from individuals, underscoring the pressing demand for privacy measures that are not only effective and robust against potential attacks but also transparent and firmly grounded in logic and mathematics.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A current way to define privacy in the context of data sharing is the promess of the dataholder (the person or entity managing the data) towards the users, that there will be no consequences (positive or negative) induced by their consent to sharing their data.&lt;/strong&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;&lt;em&gt;Let us take a small example to illustrate and to understand the underlying complexity of this notion: we consider an entity that desires to conduct a study on the correlation between smoking and cancer risks. &lt;br&gt;
Should a smoker participate, and the study concludes that smoking indeed increases the likelihood of cancer, the repercussions for the smoker could vary.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Some negative impacts: insurance premiums could increase&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Some positive impacts: motivation to quit smoking&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;We could therefore think that privacy in this case is broken for the participant, however there is a subtility which is one of the keys to capture the nuance between the privacy of an individiual and that of a group. In this case, crucially, we cannot say privacy is breached, as the participation of the smoker should not alter the study&amp;rsquo;s outcome, i.e. from a probabilistic standpoint, whether or not the individual participates in the study will not significantly change the likelihood of the conclusion of the study. &lt;br&gt;
Formally, and to introduce some probabilities, which we will delve into further later on:&lt;/em&gt;&lt;/p&gt;
&lt;h1 style=&#34;font-size: 13px;&#34;&gt;$\mathbb{P}(result=smoking\ bad | individual\ participates) \approx \mathbb{P}(result=smoking\ bad | individual\ does\ not\ participate) $&lt;/h1&gt;
&lt;br /&gt; 
&lt;p&gt;Privacy has become a real challenge for all parties, as &lt;strong&gt;it is necesssary to find a balance between the utility of the data and the privacy guarantees of the users&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For the dataholder, the aim is to retain the wealth of data to derive useful insights. They must be able to analyse enough of the data to learn about the population without revealing any individual-specific information.&lt;/li&gt;
&lt;li&gt;For the users, they must believe that their data will be protected and that they will not be hurt by giving them. This trust in the dataholder is important to incite the users to give their data.&lt;/li&gt;
&lt;/ul&gt;
&lt;br /&gt; 
&lt;p&gt;In this paper, the aim of the authors, E. Cyffers and A. Bellet, was to show some algorithms and methods that allow to improve the privacy-utility trade-offs and therefore reinforce privacy around the data, while keeping scalability.&lt;/p&gt;
&lt;p&gt;The proposed algorithms are based on &lt;strong&gt;full decentralization&lt;/strong&gt;, and &lt;strong&gt;newtork differential privacy (DP)&lt;/strong&gt;, two notions that we will explain right below.&lt;/p&gt;
&lt;br /&gt;
&lt;h1 id=&#34;section-2&#34;&gt;&lt;h1 style=&#34;font-size: 20px;&#34;&gt;Theoretical Aspects on Differential Privacy&lt;/h1&gt;&lt;/h1&gt;
&lt;h2 id=&#34;mathematical-context&#34;&gt;&lt;h1 style=&#34;font-size: 18px;&#34;&gt;Mathematical context&lt;/h1&gt;&lt;/h2&gt;
&lt;p&gt;We must introduce some key mathematical definitions to understand the problem we want to tackle.&lt;/p&gt;
&lt;h2 id=&#34;users-space&#34;&gt;Users space&lt;/h2&gt;
&lt;p&gt;We consider a set of $n$ users (e.g. a population responding to a survey), each holding a private dataset that we note $D_u$ (e.g. their answer to the questions of the survey).&lt;/p&gt;
&lt;p&gt;&lt;img
  src=&#34;./images/Sarah_Abbana/users-space.png&#34;
  alt=&#34;&#34;
  loading=&#34;lazy&#34;
  decoding=&#34;async&#34;
  class=&#34;full-width&#34;
/&gt;

&lt;/p&gt;
&lt;h2 id=&#34;neighboring-relation&#34;&gt;Neighboring relation&lt;/h2&gt;
&lt;p&gt;We write $D=D_1 \cup \cdots \cup D_n$ the union of all users datasets.&lt;/p&gt;
&lt;p&gt;We can define a &lt;strong&gt;neighboring relation&lt;/strong&gt; over these datasets, that we call user-level Differential Privacy: &lt;br&gt;
For two datasets $D$ and $D&amp;rsquo;$ of the same size, we denote by $D \sim_u D^{\prime}$ the fact that $D$ and $D&amp;rsquo;$ are neighbors, in the sense that they only differ on user $u$&amp;rsquo;s data.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;For example, $D$ and $D&amp;rsquo;$ could be two datasets corresponding to the answers of a survey from 10 users. For nine of these users the answers are the same for the two datasets. But for one user $u$, the answers are different (e.g. in $D$ user $u$ smokes, in $D&amp;rsquo;$ he doesn&amp;rsquo;t smoke).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The inuition between this definition relatively to privacy is that compared to traditional differential privacy, which considers changes in individual data points, user-level DP provides stronger privacy guarantees. By hiding the influence of an entire user&amp;rsquo;s dataset, rather than just a single data point, it ensures that individual user contributions are not discernible, thus enhancing overall privacy protection.&lt;/p&gt;
&lt;h2 id=&#34;decentralization&#34;&gt;Decentralization&lt;/h2&gt;
&lt;p&gt;We will set ourselves in a fully decentralized system. In this configuration, each user only communicates with a small number of other users at each step, and there is no central coordinator processing all the data. The aim of this setting is to limit the concentration of sensitive information in one place, reducing the risk of data breaches and unauthorized access.&lt;/p&gt;
&lt;p&gt;The users and their communications are represented by a network (directed or undirected) graph $G = (V, E)$, where $V$ is the users ensemble defined above, and $E$ is the set of edges: $(u, v) \in E$ indicates that user $u$ can send messages to user $v$.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;In this case, a randomised decentralized algorithm is defined as a mapping that from a dataset, returns that transcript of all messages exchanges between the users over the network. In formal terms, $A: D \longmapsto {(u, m, v): u \text{ sent message with content } m \text{ to } v }$.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;The aim of decentralization in this representation, is to give users the fewer information possible, i.e. only the messages they are involved in, and not the full transcript $A(D)$.&lt;/p&gt;
&lt;p&gt;We introduce this view of a user $u$: $\mathcal{O}_u(\mathcal{A}(D))=\left(\left(v, m, v^{\prime}\right) \in \mathcal{A}(D): v=u \text { or } v^{\prime}=u\right)$&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id=&#34;differential-privacy&#34;&gt;&lt;h1 style=&#34;font-size: 18px;&#34;&gt;Differential Privacy&lt;/h1&gt;&lt;/h2&gt;
&lt;p&gt;We will take a step back on this representation to introduce in a more global way the mathematical notion of Differential Privacy (DP).&lt;/p&gt;
&lt;p&gt;Let us consider a randomised algorithm $M$. $M$ is said to be &amp;ldquo;$\alpha$-differentially private&amp;rdquo; if, for any event $A$:&lt;/p&gt;
&lt;p&gt;$$\mathbb{P}[M(D)\in A]\leq e^{\alpha} \cdot \mathbb{P}[M(D&amp;rsquo;)\in A]$$&lt;/p&gt;
&lt;p&gt;where $D$ and $D&amp;rsquo;$ are two datasets differing on a single element.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;To make this more intuitive, a randomized algorithm is an algorithm that employs a degree of randomness as part of its logic. The algorithm must treat the data so that the output is not overly depend on the data of any one individual.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s consider the event &amp;ldquo;Smoking is correlated to cancer&amp;rdquo;, and $D$ and $D&amp;rsquo;$ differing on the user $u$&amp;rsquo;s data, whether or not that individual that has cancer smokes or not.&lt;/p&gt;
&lt;p&gt;We can rewrite the definition as: $\frac{\mathbb{P}\left[M\left(D\right) \in A\right]}{\mathbb{P}\left[M\left(D&amp;rsquo;\right) \in A\right]} \leq e^{\alpha}$&lt;/p&gt;
&lt;p&gt;We can see that $\alpha$, the privacy factor, represents the lost of privacy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;When $\alpha \rightarrow 0$: the two probabilities are equal, meaning that whether user $u$ participates or not to the survey, the result is the same, i.e. privacy is at its maximum, but the statistical utility is null.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When $\alpha \rightarrow+\infty$: there are no constraints on the probabilities and therefore no constraints on privacy.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus it is the intermediate case for $\alpha$ that is the most interesting and that can allow a good trade-off between privacy and utility.&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id=&#34;network-differential-privacy&#34;&gt;Network Differential Privacy&lt;/h2&gt;
&lt;p&gt;In this paper, the definition used for Differential Privacy is a bit different, actually relaxed as the algorithm is decentralized.&lt;/p&gt;
&lt;p&gt;An algorithm $A$ is said to be $(\varepsilon, \delta)$-network Differentially Private if for all pairs of distinct user $u, v \in V$ and all pairs of neighboring datasets $D \sim_u D^{\prime}$, we have:&lt;/p&gt;
&lt;p&gt;$$ \mathbb{P}\left(\mathcal{O}_v(\mathcal{A}(D))\right) \leq e^{\varepsilon} \mathbb{P}\left(\mathcal{O}_v\left(\mathcal{A}\left(D^{\prime}\right)\right)\right)+\delta $$&lt;/p&gt;
&lt;p&gt;We can interpret this as the need that the information gathered by $v$ during the execution of $A$ must not depend too much on $u$&amp;rsquo;s data.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;Furthermore, the definition can be extended in the case of collusion between the users, i.e. if multiple individuals collaborate or conspire to exploit or manipulate a system or process for their collective benefit.&lt;/p&gt;
&lt;p&gt;An algorithm $A$ is $(c, \varepsilon, \delta)$-network DP if for each user $u$, all subsets $W \subset V$ such that $\left|W\right| \leq c$, and all pairs of neighboring datasets $D \sim_u D^{\prime}$, we have:&lt;/p&gt;
&lt;p&gt;$$ \mathbb{P}\left(\mathcal{O}_W(\mathcal{A}(D))\right) \leq e^{\varepsilon} \mathbb{P}\left(\mathcal{O}_W\left(\mathcal{A}\left(D^{\prime}\right)\right)\right)+\delta $$&lt;/p&gt;
&lt;p&gt;Here $\mathcal{O}_W$ represents the aggregated information of the collusion: $\mathcal{O}_W = \cup _{w \in W} \mathcal{O}_w$.&lt;/p&gt;
 &lt;br /&gt;
&lt;h2 id=&#34;decentralized-computation-model&#34;&gt;Decentralized computation model&lt;/h2&gt;
&lt;p&gt;The algorithms studied in this paper are meant to perform computations by using a token that will walk through the nodes of the network graph. The purpose of the token is to facilitate sequential updates across the nodes in the network. As it traverses through the nodes following the edges of the graph, it carries information and updates its states based on local computations performed at each node from the values obtainable from the corresponding user.&lt;/p&gt;
&lt;p&gt;If the token $\tau$ resides at some node $u$, it will be:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Updated by: $\tau \leftarrow \tau+x_u^k, \quad$ with $x_u^k=g^k\left(\tau ; D_u\right)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sent to another user $v$ with $(u, v) \in E$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here, $x_u^k$ denotes the contribution of user $u$ to the computation. It depends both on the current value of $\tau$ and on the number of times $k$ that the token visited $u$ so far.&lt;/p&gt;
&lt;p&gt;This model of computation allows to optimize the combination of local costs within the network, which is useful for tasks like training machine learning models. The token holds the model&amp;rsquo;s parameters and is updated based on the local information at each point it visits. This decentralized approach can also be used to calculate summaries of data contributed by users, such as finding totals or averages.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;&lt;em&gt;The idea of the following parts is to study different graph achitectures and computation protocols, based on the formalization explained above, to achieve good utility-privacy trade-offs&lt;/em&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;h1 id=&#34;section-3&#34;&gt;&lt;h1 style=&#34;font-size: 20px;&#34;&gt;First case: walk on a ring&lt;/h1&gt;&lt;/h1&gt;
&lt;p&gt;We consider here a graph architecture of a directed ring, i.e. $E = {(u, u+1)}_{u=1}^{n-1} \cup{(n, 1)}$, meaning that the token, starting from the first user, will travel around the ring multiple times, and more precisely go through every user $K$ times.&lt;/p&gt;
&lt;p&gt;&lt;img
  src=&#34;./images/Sarah_Abbana/walk-on-ring.png&#34;
  alt=&#34;&#34;
  loading=&#34;lazy&#34;
  decoding=&#34;async&#34;
  class=&#34;full-width&#34;
/&gt;

&lt;/p&gt;
&lt;p&gt;This is a simple case that is meant to show how we can achieve suitable results without relying on a centralised agregator.&lt;/p&gt;
&lt;p&gt;We are going to explain how this architecture can perform for privacy guarantees on the task of &lt;em&gt;Real Summation&lt;/em&gt;, and then on &lt;em&gt;Discrete Histogram Computation&lt;/em&gt;.&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id=&#34;real-summation&#34;&gt;Real Summation&lt;/h2&gt;
&lt;p&gt;Each user will contribute a value during each round of the token&amp;rsquo;s journey. The task of &lt;em&gt;real summation&lt;/em&gt; aims to estimate the sum of all contributions made by users.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;For example, we can imagine a scenario where users of a health monitoring app report their daily step counts. The app&amp;rsquo;s goal is to calculate the total number of steps taken by all users, without revealing individual step counts. Each user&amp;rsquo;s daily step count is considered a contribution, and the app needs to aggregate these contributions while preserving user privacy.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Indeed to preserve privacy in this case, a common method is to add random noise, an abstract perturbation mechanism, which usually consist in a standard Gaussian or Laplace deviation to the contribution. We won&amp;rsquo;t go into further details on the perturbation, but we assume that it satisfies traditional local differntial privacy (LDP).&lt;/p&gt;
&lt;p&gt;Furthermore, here the decentralized protocol proposes to add this noise only once every few hops of the token, and in fact every $n-1$ hops of the token as shown in the algorithm below:&lt;/p&gt;
&lt;p&gt;&lt;img
  src=&#34;./images/Sarah_Abbana/algo1.png&#34;
  alt=&#34;&#34;
  loading=&#34;lazy&#34;
  decoding=&#34;async&#34;
  class=&#34;full-width&#34;
/&gt;

&lt;/p&gt;
&lt;p&gt;They prove the following theorem:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem:&lt;/strong&gt; Let $\varepsilon, \delta&amp;gt;0$. Algorithm 1 outputs an unbiased estimate of $\bar{x}$ with standard deviation $\sqrt{\left\lfloor \frac{Kn}{n - 1} \right\rfloor} \sigma_{\text{loc}}$, and is $\sqrt{2K \ln\left(\frac{1}{\delta&amp;rsquo;}\right)\varepsilon}$ $+ K\epsilon(e^\varepsilon - 1), K\delta + \delta&amp;rsquo;$-network DP for any $\delta&amp;rsquo; &amp;gt; 0$&lt;/p&gt;
&lt;p&gt;The Algorithm 1 proposed actually provides a gain on the error of $O\left(\frac{1}{\sqrt{n}}\right)$ compared to a LDP achieving the same privacy guarantees. This means it achieves a similar balance between privacy and utility as a centralized aggregator would, if they itratively aggregated user contributions then perturb the results before sending it to the users, buy here without the need for this centralized party.&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id=&#34;discrete-histogram-computation&#34;&gt;Discrete Histogram Computation&lt;/h2&gt;
&lt;p&gt;Here we focus on another task that is computing histograms over a discrete domain.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;With the same example as above, it could be such as counting the frequency of steps in different ranges for a health monitoring app.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Traditional local differential privacy (LDP) methods use L-ary randomized response, where each user submits their true value with probability $1-\gamma$ and a random value with probability $\gamma$. However, in the decentralized approach with a ring network, they propose Algorithm 2. This algorithm randomizes each user&amp;rsquo;s contribution using L-ary randomized response before adding it to the token, which maintains a partial histogram representing the shuffled contributions, thus enhancing privacy through shuffling, as demonstrated in previous studies.&lt;/p&gt;
&lt;p&gt;&lt;img
  src=&#34;./images/Sarah_Abbana/algo2.png&#34;
  alt=&#34;&#34;
  loading=&#34;lazy&#34;
  decoding=&#34;async&#34;
  class=&#34;full-width&#34;
/&gt;

&lt;/p&gt;
&lt;p&gt;As for the case of real summation, a theorem proves that to achieve the same privacy in LDP, it would need $\sqrt n$ times more random responses, and when achieving the same utility (meaning to fix $\gamma$), Algorithm 2 provides a gain of privacy of $O\left(\frac{1}{\sqrt{n}}\right)$.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;We see that decentralized computation over a ring enables comparable utility to a trusted aggregator by sequentially hiding previous users&amp;rsquo; contributions, without relying on a central server or requiring costly multi-party computation protocols.&lt;/p&gt;
&lt;p&gt;However this simple topology presents limitations including vulnerability to collusions, which compromises differential privacy guarantees, and inadequacy for extensions to gradient descent due to the lack of privacy amplification between users with fixed positions in the ring.&lt;/p&gt;
&lt;p&gt;This is why we shall now consider random walks over a complete graph.&lt;/p&gt;
&lt;br/&gt;
&lt;h1 id=&#34;section-4&#34;&gt;&lt;h1 style=&#34;font-size: 20px;&#34;&gt;Generalisation: walk on a complete graph&lt;/h1&gt;&lt;/h1&gt;
&lt;p&gt;Random walk on a complete graph assumes the token is randommly sent to a user at each step. The walk consists of fixed-length random walks, ensuring that each user&amp;rsquo;s contributions are random, and their path is concealed, allowing only the messages sent and received to be known by a user.&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id=&#34;real-summation-1&#34;&gt;Real Summation&lt;/h2&gt;
&lt;p&gt;Algorithm 3 shows the protocol, naturally extended from the ring topology, where each user updates the token with its contribution and a perturbation. The secrecy of the path taken by the token and the aggregations of the contributions between two visits of the token guarantee the network DP property.&lt;/p&gt;
&lt;p&gt;&lt;img
  src=&#34;./images/Sarah_Abbana/algo3.png&#34;
  alt=&#34;&#34;
  loading=&#34;lazy&#34;
  decoding=&#34;async&#34;
  class=&#34;full-width&#34;
/&gt;

&lt;/p&gt;
&lt;p&gt;Again, a theorem proves that asymptotically, network DP offers a privacy amplification of $O\left(\frac{1}{\sqrt{n}}\right)$ over LDP for the same conditions, which aligns with the privacy-utility trade-off of a trusted aggregtor.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;The same analysis can be done for the discrete histogram computation case.&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id=&#34;stochastic-gradient-descent&#34;&gt;Stochastic Gradient Descent&lt;/h2&gt;
&lt;p&gt;In this section, we address the challenge of private convex optimization using stochastic gradient descent (SGD). We consider a convex set $(W \subseteq \mathbb{R}^d)$ and a collection of convex functions $(f(\cdot; D_1), \ldots, f(\cdot; D_n))$, each associated with a user, being L-Lipschitz and $(\beta)$-smooth over $(W)$. Our goal is to privately solve the optimization problem to find $(w^*)$ minimizing the average of these functions over $(W)$:&lt;/p&gt;
&lt;p&gt;$$w^* \in \arg \min_{w \in \mathcal{W}} \left( F(w):=\frac{1}{n} \sum_{u=1}^n f\left(w ; D_u\right) \right)$$&lt;/p&gt;
&lt;p&gt;This equation encapsulates various machine learning tasks, such as ridge and logistic regression, and others. This is significant because it addresses the need for private optimization in machine learning, ensuring that sensitive data remains protected while training models on distributed datasets.&lt;/p&gt;
&lt;p&gt;The algorithm below proposes a method to privately approximate $w^*$, where the token represents the current iterate. At each step, the user $u$ holding the token performs a projected noisy gradient step and sends the updated token to a random user. The variance in the Gaussian mechanism of line 4 is deduced from the Lipschitz property of the functions.&lt;/p&gt;
&lt;p&gt;&lt;img
  src=&#34;./images/Sarah_Abbana/algo4.png&#34;
  alt=&#34;&#34;
  loading=&#34;lazy&#34;
  decoding=&#34;async&#34;
  class=&#34;full-width&#34;
/&gt;

&lt;/p&gt;
&lt;p&gt;A theorem based on the evolution of the privacy loss proves the differential privacy guarantees, and again the results are satisfactory. Compared to traditional local differential privacy methods, we obtain a privacy amplification of $O\left(\frac{\ln n}{\sqrt{n}}\right)$ for a specific number of iterations, with the same level of privacy-utility trade-off.&lt;/p&gt;
&lt;p&gt;With a fixed privacy budget and a large number of iteration, the expected error of this algorithm is smaller with this network DP than with LDP.&lt;/p&gt;
&lt;br /&gt;
&lt;p&gt;Compared to the ring case, this random walk approach has better robustness to collusion, as colluding users can be treated as a single node with adjusted transition probabilities, leading to equivalent privacy guarantees as for non-colluding users.&lt;/p&gt;
&lt;br/&gt;
&lt;h1 id=&#34;section-5&#34;&gt;&lt;h1 style=&#34;font-size: 20px;&#34;&gt;Experiments&lt;/h1&gt;&lt;/h1&gt;
&lt;p&gt;To show the efficiency of the privacy amplification methods explained in this article, some experiments have been made on the complete graph, first for the Real Summation task, and then for Machine Learning with Stochastic Gradient Descent (SGD).&lt;/p&gt;
&lt;p&gt;The code is available here: &lt;a href=&#34;https://github.com/totilas/privacy-amplification-by-decentralization/tree/main&#34;&gt;Github Link&lt;/a&gt;&lt;/h1&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;h2 id=&#34;real-summation-2&#34;&gt;Real Summation&lt;/h2&gt;
&lt;p&gt;We reproduced the first experiment from the paper, comparing th analytical bounds of LDP and NDP on the real summation task.&lt;/p&gt;
&lt;p&gt;To do so, we only need to run the &lt;em&gt;main_a.py&lt;/em&gt; and &lt;em&gt;main_b.py&lt;/em&gt; files with python from the &lt;em&gt;fig1&lt;/em&gt; folder to display the corresponding figures (a) and (b). It works, for instance, with Python version 3.8, with the prerequisite of having installed the packages &lt;em&gt;numpy&lt;/em&gt; and &lt;em&gt;matplotlib&lt;/em&gt;, only taking a few seconds to execute.&lt;/p&gt;
&lt;p&gt;It gives the following results:&lt;/p&gt;
&lt;p&gt;&lt;img
  src=&#34;./images/Sarah_Abbana/results1.png&#34;
  alt=&#34;&#34;
  loading=&#34;lazy&#34;
  decoding=&#34;async&#34;
  class=&#34;full-width&#34;
/&gt;

&lt;/p&gt;
&lt;p&gt;As we may see from the theoretical bounds, privacy is amplified with network differential privacy over LDP when the numer of users $n$ is greater or equal to 20, with increaingly substancial improvements as $n$ grows.&lt;/p&gt;
&lt;p&gt;In practice by making some simulations, the gains are even more significant and even for a smaller number of users, as we see in figure (b).&lt;/p&gt;
&lt;br/&gt;
&lt;h2 id=&#34;machine-learning-with-sgd&#34;&gt;Machine Learning with SGD&lt;/h2&gt;
&lt;p&gt;For this second experiment, the task is to train a logistic regression model in this decentralized context.&lt;/p&gt;
&lt;p&gt;The setting of the experiment is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UCI Housing dataset (binarized version)&lt;/li&gt;
&lt;li&gt;Standardized features and normalized data point (to have unit L2 norm and Lipschitz property of the logistic loss)&lt;/li&gt;
&lt;li&gt;Train/test split of 80% uniformly at random&lt;/li&gt;
&lt;li&gt;Training set split between $n = 2000$ users (each user has a local dataset of size $8$)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The experiment compares three settings for Stochastic Gradient Descent with perturbation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Centralized DP-SGD, requiring a trusted curator&lt;/li&gt;
&lt;li&gt;Local DP-SGD, corresponding to Algorithm 4 with LDP method&lt;/li&gt;
&lt;li&gt;Network DP-SGD, corresponding to Algorithm 4 with Network DP method, the one of interest&lt;/li&gt;
&lt;/ul&gt;
&lt;br/&gt;
&lt;p&gt;We must run the &lt;em&gt;main.py&lt;/em&gt; file of folder &lt;em&gt;fig2&lt;/em&gt; with Python to display the results.&lt;/p&gt;
&lt;p&gt;It is possible to use the command &lt;em&gt;python main.py &amp;ndash;help&lt;/em&gt; to show the list of parameters that can be tuned to modify the context of the experiment (the default ones are for $\varepsilon = 10$ and $\varepsilon = 1$):&lt;/p&gt;
&lt;p&gt;&lt;img
  src=&#34;./images/Sarah_Abbana/options.png&#34;
  alt=&#34;&#34;
  loading=&#34;lazy&#34;
  decoding=&#34;async&#34;
  class=&#34;full-width&#34;
/&gt;

&lt;/p&gt;
&lt;p&gt;I had some issues to run this program with my settings (same as for the first experiment).&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &lt;em&gt;typer&lt;/em&gt; module was missing therefore I had to install it : &lt;em&gt;pip install typer&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;_intercept_dot&lt;/em&gt; function from &lt;em&gt;sklearn.linear_model._logistic&lt;/em&gt; couldn&amp;rsquo;t be found either. By checking the &lt;em&gt;sklearn.linear_model.LogisticRegression&lt;/em&gt; (which is the public class corresponding to the import here), this function doesn&amp;rsquo;t appear. I wanted to change it with the &lt;em&gt;intercept_&lt;/em&gt; attribute but it didn&amp;rsquo;t fit either. Then by checking the usage of this function in the case, it seemed that it computes a dot product between the model parameters and the input data, taking into account whether an intercept term is included. Therefore I tried to manually code this functionality but unfortunately it didn&amp;rsquo;t give coherent results compared to the paper.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here are the original results from the paper:&lt;/p&gt;
&lt;p&gt;&lt;img
  src=&#34;./images/Sarah_Abbana/results2.png&#34;
  alt=&#34;&#34;
  loading=&#34;lazy&#34;
  decoding=&#34;async&#34;
  class=&#34;full-width&#34;
/&gt;

&lt;/p&gt;
&lt;p&gt;Here, although the number of contributions per user doesn&amp;rsquo;t align with the optimal regime for network DP, the observed privacy amplification surpasses theoretical expectations. By numerically determining the minimum noise level required for theoretical proofs, they demonstrated that Network DP-SGD achieves a privacy-utility trade-off comparable to Centralized DP-SGD across various privacy levels, showcasing significant privacy amplification benefits over Local DP-SGD, especially in scenarios with fewer iterations than typically recommended.&lt;/p&gt;
&lt;br/&gt;
&lt;h1 id=&#34;section-6&#34;&gt;&lt;h1 style=&#34;font-size: 20px;&#34;&gt;Perspectives&lt;/h1&gt;&lt;/h1&gt;
&lt;p&gt;The work presented suggests numerous avenues for exploration. Generalizations to diverse graph structures, incorporating dynamic topologies to reinforce resilience against collusion, and investigating decentralized models beyond our current scope are key directions. Exploring the potential of multiple tokens traversing the graph simultaneously and delving into randomized gossip algorithms offer promising avenues for advancing privacy-preserving techniques. Finally, probing the theoretical limits of network DP and exploring scenarios where users trust nearby peers more could provide insights into refining privacy mechanisms.&lt;/p&gt;
&lt;style TYPE=&#34;text/css&#34;&gt;
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
&lt;/style&gt;
&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],
        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry
    }
});
MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;
    }
});
&lt;/script&gt;
&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;</description>
      <author>Students from M2 Data Science IP Paris</author>
      <guid>http://localhost:1313/posts/privacy-amplification/</guid>

      <pubDate>Wed, 27 Mar 2024 12:05:50 +0100</pubDate>
      <guid>http://localhost:1313/posts/privacy-amplification/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Privacy Amplification by Decentralization&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Author: Sarah ABBANA BENNANI &lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction - the challenge of data privacy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Theoretical Aspects on Differential Privacy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;First Case: walk on a ring&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Generalisation: walk on a complete graph&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Experiments&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Perspectives&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br /&gt;&#xD;&#xA;&lt;p&gt;This is a blogpost about the paper  Privacy Amplification by Decentralization, published by E. Cyffers et al. in 2022 and available &lt;a href=&#34;https://proceedings.mlr.press/v151/cyffers22a/cyffers22a.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;section-1&#34;&gt;&lt;h1 style=&#34;font-size: 20px;&#34;&gt;Introduction - the challenge of data privacy&lt;/h1&gt;&lt;/h1&gt;&#xA;&lt;p&gt;In recent years, the concept of privacy has gained significant attention due to the proliferation of data collection practices and the need to safeguard individuals&amp;rsquo; personal information. &lt;br&gt;&#xA;There has been a notable shift towards implementing regulations to govern the gathering of data from individuals, underscoring the pressing demand for privacy measures that are not only effective and robust against potential attacks but also transparent and firmly grounded in logic and mathematics.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Robust or Fair</title>
      <link>http://localhost:1313/posts/robust-or-fair/</link>
      <pubDate>Wed, 27 Mar 2024 11:37:03 +0100</pubDate>
      <guid>http://localhost:1313/posts/robust-or-fair/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;To be Robust or to be Fair: Towards Fairness in Adversarial Training&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Authors: Maryem Hajji &amp; Cément Teulier&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Initial Analysis&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2.1&#34;&gt;Previous Studies&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2.2&#34;&gt;Theoretical Demonstration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Model&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3.1&#34;&gt;Fairness Requirements&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3.2&#34;&gt;Practical Algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Experimentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;This blog post retraces the study conducted in the &lt;a href=&#34;http://proceedings.mlr.press/v139/xu21b.html&#34;&gt;paper&lt;/a&gt; &amp;ldquo;To be Robust or to be Fair: Towards Fairness in Adversarial Training&amp;rdquo; and written by Han Xu, Xiaorui Liu, Yaxin Li, Yaxin Li, Anil K. Jain and Jiliang Tang.&lt;/p&gt;</description>
    </item>
    <item>
      <title>XCM, an explainable CNN for MTS classficiation</title>
      <link>http://localhost:1313/posts/xcm/</link>
      <pubDate>Tue, 26 Mar 2024 00:55:40 +0100</pubDate>
      <guid>http://localhost:1313/posts/xcm/</guid>
      <description>&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;    tex2jax: {&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 36px;&#34;&gt;XCM: An Explainable Convolutional Neural Network for Multivariate Time Series Classification&lt;/h1&gt;&#xD;&#xA;&lt;h3 style=&#34;font-size: 24px;&#34;&gt;Authors : Nicolas SAINT &amp; Matthis Guérin&lt;/h3&gt;&#xD;&#xA;&lt;h4 style=&#34;font-size: 22px;&#34;&gt;Table of Contents&#xD;&#xA;&lt;/h4&gt;&#xD;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#2-related-work&#34;&gt;2. Related Work&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#3-xcm&#34;&gt;3. XCM&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#4-evaluation&#34;&gt;4. Evaluation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#5-results&#34;&gt;5. Results&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#6-implementation&#34;&gt;6. Implementation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#7-conclusion&#34;&gt;7. Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the article &amp;ldquo;XCM: An Explainable Convolutional Neural Network for Multivariate Time Series Classification&amp;rdquo; published by Kevin Fauvel et al. in 2021 and available &lt;a href=&#34;https://www.mdpi.com/2227-7390/9/23/3137&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>RobustAI_RegMixup</title>
      <link>http://localhost:1313/posts/robustai_regmixup/</link>
      <pubDate>Sun, 24 Mar 2024 12:38:16 +0100</pubDate>
      <guid>http://localhost:1313/posts/robustai_regmixup/</guid>
      <description>&lt;style&#xD;&#xA;TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;&#xD;&#xA;code.has-jax {font:&#xD;&#xA;inherit;&#xD;&#xA;font-size:&#xD;&#xA;100%; &#xD;&#xA;background: &#xD;&#xA;inherit; &#xD;&#xA;border: &#xD;&#xA;inherit;}&#xD;&#xA;&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;!DOCTYPE html&gt;&#xD;&#xA;&lt;html lang=&#34;en&#34;&gt;&#xD;&#xA;&lt;head&gt;&#xD;&#xA;&lt;meta charset=&#34;UTF-8&#34;&gt;&#xD;&#xA;&lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;&#xD;&#xA;&lt;title&gt;Styled Table&lt;/title&gt;&#xD;&#xA;&lt;style&gt;&#xD;&#xA;    table {&#xD;&#xA;        border-collapse: collapse;&#xD;&#xA;        width: 100%;&#xD;&#xA;    }&#xD;&#xA;    th, td {&#xD;&#xA;        padding: 8px;&#xD;&#xA;        text-align: center;&#xD;&#xA;        border-bottom: 1px solid #ddd;&#xD;&#xA;    }&#xD;&#xA;    th {&#xD;&#xA;        background-color: #f2f2f2;&#xD;&#xA;    }&#xD;&#xA;    tr:hover {&#xD;&#xA;        background-color: #f5f5f5;&#xD;&#xA;    }&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;/head&gt;&#xD;&#xA;&lt;/html&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 36px;&#34;&gt;RegMixup : Regularizer for robust AI&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Improve accuracy and Out-of-Distribution Robustness&lt;h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 18px;&#34;&gt;Authors: Marius Ortega, Ly An CHHAY &lt;br /&gt;&#xD;&#xA;Paper : &lt;a href=&#34;https://arxiv.org/abs/2206.14502&#34;&gt;RegMixup&lt;/a&gt;  by Francesco Pinto, Harry Yang, Ser-Nam Lim, Philip H.S. Torr, Puneet K. Dokania&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0.0&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0.1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Prerequisites&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.1&#34;&gt;Empirical Risk Minimization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.2&#34;&gt;Vicinal Risk Minimization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1.3&#34;&gt;Mixup&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;RegMixup in theory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;RegMixup in practice &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0.0&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;In this blog post, we will present the paper &amp;ldquo;RegMixup: Regularizer for robust AI&amp;rdquo; by Francesco Pinto, Harry Yang, Ser-Nam Lim, Philip H.S. Torr, Puneet K. Dokania. This paper introduces a new regularizer called RegMixup, which is designed to improve the accuracy and out-of-distribution robustness of deep neural networks. The authors show that RegMixup can be used to improve the performance of state-of-the-art models on various datasets, including CIFAR-10, CIFAR-100, and ImageNet. The paper also provides an extensive empirical evaluation of RegMixup, demonstrating its effectiveness in improving the robustness of deep neural networks to out-of-distribution samples.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints</title>
      <link>http://localhost:1313/posts/lambert-davy/</link>
      <pubDate>Sat, 23 Mar 2024 19:39:13 +0100</pubDate>
      <guid>http://localhost:1313/posts/lambert-davy/</guid>
      <description>&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 18px;&#34;&gt;Authors: Godefroy LAMBERT and Louise DAVY&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Definitions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;AUC-based fairness constraints&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;ROC-based fairness constraints&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Results&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Reproducibility&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-7&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints, published by R. Vogel et al. in 2021 and available &lt;a href=&#34;http://proceedings.mlr.press/v130/vogel21a/vogel21a-supp.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h1 id=&#34;section-1&#34;&gt;&lt;h1 style=&#34;font-size: 24px; text-decoration: underline;&#34;&gt;Introduction&lt;/h1&gt;&lt;/h1&gt;&#xA;&lt;p&gt;With recent advances in machine learning, applications are becoming increasingly numerous and the expectations are high. Those applications will only be able to be deployed if some important issues are addressed such as bias. There are famous datasets known for containing variables that induce a lot of bias such as Compas with racial bias and gender bias in the Adult dataset. To avoid those biases, new algorithms were created to provide more fairness in the prediction by using diverse methods.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Label-Free Explainability</title>
      <link>http://localhost:1313/posts/label-free-explainability/</link>
      <pubDate>Sun, 17 Mar 2024 15:31:34 +0100</pubDate>
      <guid>http://localhost:1313/posts/label-free-explainability/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Label-Free Explainability for Unsupervised Models&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 18px;&#34;&gt;Authors: &lt;a href=&#34;https://github.com/Valentinahxu&#34;&gt;Valentina Hu &lt;/a&gt; and  &lt;a href=&#34;https://github.com/selmazrg&#34;&gt; Selma Zarga&lt;/a&gt;&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Incentives&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Feature Importance &lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Example Importance&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Experiment&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper Label-Free Explainability for Unsupervised Models, published by J. Crabbé et al. in 2022 and available &lt;a href=&#34;https://proceedings.mlr.press/v162/crabbe22a/crabbe22a.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;section-0&#34;&gt;Why do we need explainability ?&lt;/h2&gt;&#xA;&lt;p&gt;Machine learning models are becoming increasingly capable of making advanced predictions. While models like linear regression are relatively easy to understand and explain, more complex models, often called &lt;strong&gt;&amp;ldquo;black boxes&amp;rdquo;&lt;/strong&gt; due to their complexity, present challenges in explaining how they make predictions. These models can be problematic in highstakes applications such as healthcare, finance, and justice, where it&amp;rsquo;s crucial to justify decision-making. Additionally, in case of errors, it&amp;rsquo;s important to understand the origin in order to address and correct them.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Adversarially Reweighted Learning</title>
      <link>http://localhost:1313/posts/adversarially_reweighted_learning/</link>
      <pubDate>Mon, 04 Mar 2024 18:35:12 +0100</pubDate>
      <guid>http://localhost:1313/posts/adversarially_reweighted_learning/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Fairness without Demographics through Adversarially Reweighted Learning&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Authors: Pierre Fihey &amp; Guerlain Messin&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Fairness issues in ML and AI&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;The privacy of demographic’s data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;The Adversarial Reweighted Learning Model&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;An Hypothesis: Protected Groups are Correlated with Both Features and Labels&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Computational identifiability of protected groups&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;The Rawlsian Max-Min Fairness principle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;The ARL objective&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-7&#34;&gt;The Model Architecture&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-8&#34;&gt;Results analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-9&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper Fairness without Demographics through Adversarially Reweighted Learning, published by P. Lahoti et al. in 2020 and available &lt;a href=&#34;https://dl.acm.org/doi/abs/10.5555/3495724.3495786&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Packed Ensembles</title>
      <link>http://localhost:1313/posts/packed-ensembles/</link>
      <pubDate>Tue, 27 Feb 2024 15:05:20 +0100</pubDate>
      <guid>http://localhost:1313/posts/packed-ensembles/</guid>
      <description>&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;div style=&#34;text-align:center;&#34;&gt;&#xD;&#xA;This is a blog post about the paper Packed-Ensembles for Efficient Uncertainty Estimation, published by O. Laurent et al. in 2023 and available [here](https://openreview.net/pdf?id=XXTyv1zD9zD).&#xD;&#xA;&lt;h3 id=&#34;authors-cynthia-obeid-and-elie-nakad&#34;&gt;&lt;strong&gt;Authors&lt;/strong&gt;: Cynthia Obeid and Elie Nakad&lt;/h3&gt;&#xA;&lt;h1&gt;Introduction&lt;/h1&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;The document &#34;Packed-Ensembles for Efficient Uncertainty Estimation&#34; introduces a novel framework for designing and training compact, structured ensembles of neural networks, termed Packed-Ensembles (PE). It addresses the limitations of Deep Ensembles (DE) in terms of computational efficiency and hardware constraints by leveraging grouped convolutions. This technique allows for parallelizing the ensemble into a single shared backbone, improving training and inference speeds within the memory limits of standard neural networks. The paper demonstrates through extensive experiments that PEs maintain the beneficial properties of DEs, such as diversity and robustness to distribution shift, while achieving comparable accuracy, calibration, and out-of-distribution detection capabilities. The work includes implementation details, experimental results on CIFAR-10/100 and ImageNet datasets and comparisons with existing approaches. It concludes with insights on the reproducibility of results and the potential ethical considerations of deploying such models in safety-critical systems.&#xD;&#xA;&lt;div style=&#34;text-align:center;&#34;&gt;&#xD;&#xA;&lt;h1&gt;Presentation of the model&lt;/h1&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;p&gt;&lt;strong&gt;Packed-Ensembles&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Framework to Learn with Interpretation</title>
      <link>http://localhost:1313/posts/a-framework-to-learn-with-interpretation/</link>
      <pubDate>Tue, 13 Feb 2024 16:56:04 +0100</pubDate>
      <guid>http://localhost:1313/posts/a-framework-to-learn-with-interpretation/</guid>
      <description>&lt;hr&gt;&lt;/hr&gt;&#xD;&#xA;&lt;style&#xD;&#xA;TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;&lt;p&gt;code.has-jax {font:&#xA;inherit;&#xA;font-size:&#xA;100%;&#xA;background:&#xA;inherit;&#xA;border:&#xA;inherit;}&lt;/p&gt;&#xA;&lt;p&gt;&lt;/style&gt;&lt;/p&gt;&#xA;&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 36px;&#34;&gt;A Framework to Learn with Interpretation&lt;/h1&gt;&#xD;&#xA;&lt;p&gt;&lt;strong&gt;Authors: Maroun ABOU BOUTROS, Mohamad EL OSMAN&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Article: &lt;a href=&#34;https://arxiv.org/abs/2010.09345&#34;&gt;A Framework to Learn with Interpretation&lt;/a&gt; by Jayneel Parekh, Pavlo Mozharovskyi and Florence d’Alché-Buc&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>NTK-SAP: IMPROVING NEURAL NETWORK PRUNING BY ALIGNING TRAINING DYNAMICS</title>
      <link>http://localhost:1313/posts/ntk-sap/</link>
      <pubDate>Wed, 07 Feb 2024 16:07:10 +0100</pubDate>
      <guid>http://localhost:1313/posts/ntk-sap/</guid>
      <description>&lt;p&gt;This is a blog post about the paper NTK-SAP: Improving neural network pruning by aligning training dynamics, published by Y. Wang et al. in 2023 and available &lt;a href=&#34;https://openreview.net/pdf?id=-5EWhW_4qWP&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Introduction:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;In a world increasingly driven by demand for data and computational resources, the narrative of artificial intelligence has been one of abundance: more data, more power, more precision. Yet, nestled within this grand tale, lies a quieter narrative - one that champions the concept of achieving more with less—Frugal AI.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Do Perceptually Aligned Gradients imply Robustness?</title>
      <link>http://localhost:1313/posts/robustness-and-pag-the-converse/</link>
      <pubDate>Wed, 07 Feb 2024 16:06:43 +0100</pubDate>
      <guid>http://localhost:1313/posts/robustness-and-pag-the-converse/</guid>
      <description>&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;    tex2jax: {&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Robustness and Perceptually Aligned Gradients : does the converse stand ?&lt;/h1&gt;&#xD;&#xA;&lt;h3 style=&#34;font-size: 24px;&#34;&gt;Author: Yohann Zerbib&lt;/h3&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Adversarial Attacks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Perceptually Aligned Gradients&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Experiment&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;To go further&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper Do Perceptually Aligned Gradients Imply Robustness?, published by R. Ganz et al. in 2023 and available &lt;a href=&#34;https://openreview.net/pdf?id=W6topEXC2-v&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>To update or not to update? Neurons at equilibrium in deep models</title>
      <link>http://localhost:1313/posts/neq/</link>
      <pubDate>Wed, 07 Feb 2024 15:55:14 +0100</pubDate>
      <guid>http://localhost:1313/posts/neq/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;To update or not to update? Neurons at equilibrium in deep models&#xD;&#xA;&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Author: Alexis WINTER Augustin CREUSILLET&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-content&#34;&gt;Table of content&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;NEq&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Experiments&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Results&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Reproducibility&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;References&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;This is a blog post about the paper To update or not to update? Neurons at equilibrium in deep models, published by A. Bgragagnolo et al. in 2022 and available [here]https://proceedings.neurips.cc/paper_files/paper/2022/file/8b2fc235787852ead92da2268cd9e90c-Paper-Conference.pdf).&lt;/p&gt;&#xA;&lt;h2 id=&#34;section-0&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;&#xA;&lt;p&gt;Recent advances in &lt;strong&gt;deep learning&lt;/strong&gt; have undeniably propelled the field to unprecedented heights, revolutionizing various domains from computer vision to natural language processing. However, these strides forward have not come without a significant toll on computational resources. As models grow increasingly complex, the demand for &lt;strong&gt;computational power&lt;/strong&gt; has surged exponentially. One of the most expensive tasks in deep learning is undoubtedly the training of models. This process entails iteratively adjusting millions or even billions of parameters to minimize a predefined loss function, requiring extensive computational power and time-intensive operations. This process poses challenges in terms of both &lt;strong&gt;affordability and environmental sustainability&lt;/strong&gt;, highlighting the need for innovative solutions to make deep learning more efficient and accessible in the face of escalating computational demands.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Optimal Transport Based Adversarial Patch Attacks</title>
      <link>http://localhost:1313/posts/optimal_transport_based_adversarial_patch/</link>

      <description>&lt;style TYPE=&#34;text/css&#34;&gt;
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
&lt;/style&gt;
&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],
        displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],
        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry
    }
});
MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;
    }
});
&lt;/script&gt;
&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;
&lt;h1 id=&#34;authors&#34;&gt;Authors:&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Mohammed Jawhar&lt;/li&gt;
&lt;li&gt;Aymane Rahmoune&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;paper--optimal-transport-based-adversarial-based-patch-to-leverage-large-scale-attack-transferability&#34;&gt;Paper : &lt;a href=&#34;https://openreview.net/forum?id=nZP10evtkV&#34;&gt;Optimal Transport Based Adversarial Based Patch To Leverage Large Scale Attack Transferability&lt;/a&gt;&lt;/h3&gt;
&lt;h1 id=&#34;table-of-contents-&#34;&gt;Table of contents :&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Understanding Adversarial Patch Attacks&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#subsection-11&#34;&gt;Decision boundary based&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsection-12&#34;&gt;Feature point based&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsection-13&#34;&gt;Distribution based&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Transferability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Optimal Transport&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Experiments&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#subsection-41&#34;&gt;Experimental Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsection-42&#34;&gt;Results and Findings&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#subsection-421&#34;&gt;Digital Experiments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsection-422&#34;&gt;Hybrid Experiments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsection-423&#34;&gt;Physical Experiments&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Reproducibility&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;section-0&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Imagine you&amp;rsquo;re showing a picture to a friend, asking them to guess who&amp;rsquo;s in it, then sticking a tiny, almost invisible sticker on that photo. For some reason, this sticker makes your friend completely unable to recognize who&amp;rsquo;s in the picture. This might sound like magic, but something similar can happen with Computer Vision models designed to capture an image content, either through a classification, a segmentation or even a generation task. These AI programs can be vulnerable to such tricks, that we call technically, Adversarial Patch Attacks.&lt;/p&gt;
&lt;p&gt;As AI becomes increasingly integrated into various aspects of our lives, including critical applications like passport security systems, autonomous vehicles, traffic sign detection, and surgical assistance; the reliability, trustworthiness, and performance of these systems under all conditions became of prime importance. This has led to a growing interest in the area of Robust AI, which focuses on enhancing the safety and security of AI technologies by improving their resilience to adverse conditions and digital threats. Within this domain, the study of Attacks and Defense ways plays a pivotal role.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img src=&#34;./images/image_optimal_transport_patch/road_scene.png&#34; alt=&#34;Road_scene&#34;&gt;
&lt;/p&gt;
&lt;p&gt;While these attacks might not seem like a big deal, nor dangerous in this context, the consequences can be severe in critical scenarios - take for example an autonomous vehicle failing to recognize a stop sign, hurting potentially a pedestrian. In this blog we will explore a new approach used for developping such adversarial patch attacks, based on Optimal Transport, as outlined in the paper &lt;em&gt;&lt;strong&gt;Optimal Transport Based Adversarial Patch To Leverage Large Scale Attack Transferability&lt;/strong&gt;&lt;/em&gt;. We will try to follow the same structure as in the paper to make the reading easier for you, but with much more simplicity.&lt;/p&gt;
&lt;h2 id=&#34;section-1&#34;&gt;Understanding Adversarial Attacks&lt;/h2&gt;
&lt;p&gt;First thing first, let us redefine some previously mentionned concepts, while making them into context.&lt;/p&gt;
&lt;p&gt;As deep neural networks keep getting better, developers are working hard to make sure they are trustworthy and reliable. This means constantly testing them to see how well they can handle different challenges, quantifying their robustness, and developping some robustification methods. In the context of image classification for instance, one way to do this is by designing adversarial attacks, which consists of a perturbation or noise, sometimes invisible patterns added to the input images in order to confuse the model and make it misclassify them, causing a huge drop in the accuracy.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Adversarial Patch Attacks&lt;/strong&gt; are a specific type that consists of altering only a small part(patch) of the input, either physically or digitally by inserting a crafted &amp;ldquo;sticker&amp;rdquo;. These attacks happen to be more threatful as they can be easily applied in real life, they do not require modification of the entire image, and they can fool multiple, vastly different models with the same crafted patch. This last property is called &lt;strong&gt;transferability&lt;/strong&gt; and aims to test these engineered adversarial patches on various target models, beyond the original one used for learning, even if the two models(source and target) have been trained on different data or use different architectures, to evaluate the attack&amp;rsquo;s efficacy, and measure the models robustness.&lt;/p&gt;
&lt;p&gt;Despite the fact that crafting adversarial patch attacks is mainly based around maximizing the classification error through a gradient ascent, we can differenciate between three distinct approaches:&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img src=&#34;./images/image_optimal_transport_patch/APA_strategies.png&#34; alt=&#34;APA_strategies&#34;&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Decision boundaries based :&lt;/strong&gt; &lt;a name=&#34;subsection-11&#34;&gt;&lt;/a&gt; Which is the most applied approach in previous works and litterature. It focuses on pushing the image&amp;rsquo;s representation in the neural network&amp;rsquo;s &lt;strong&gt;decision&lt;/strong&gt; space, across the decision boundary, making the network perceive it as belonging to a different, probability maximized class.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;To simplify this approach, imagine a group of fans attempting to sneak into a VIP section at a concert by dressing in a fancy way, like known VIP guests(targeted class). The idea is to blend in so well that they are indistinguishable from actual VIPs to the security guards (the ML model). Despite the simplicity and goodness of this strategy, it has some drawbacks :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It is highly dependant on the model on which the attack is based, which makes it not really transferable: The success of this method hinges on the security&amp;rsquo;s lack of detail. If they are controlled by another security gard who is very familiar with the actual VIPs, the disguises will fail.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The patch may push the corrupted image representations into unknown regions of the representation space: In their attempt to mimic the VIPs, there&amp;rsquo;s a risk that their disguises might be so overdone that they don&amp;rsquo;t resemble any actual VIPs, pushing them to have a weird unique look. Hence, they end up in a no-man&amp;rsquo;s-land, not fitting in with either the regular attendees or the VIPs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Feature point based :&lt;/strong&gt; &lt;a name=&#34;subsection-12&#34;&gt;&lt;/a&gt;Instead of crossing a decision boundary, this strategy aims to modify the input so its representation in the &lt;strong&gt;feature space&lt;/strong&gt; matches the one of a target point belonging to a different class. This is like fine-tuning the attack to match a specific &amp;ldquo;signature&amp;rdquo; that the model associates to a specific point.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Revisiting our concert analogy, consider the fans now opting to mimic a specific celebrity known to be attending the concert, assuming that matching this one high-profile individual&amp;rsquo;s appearance will guarantee them entry. Although it seems more precise and effective than the first approach, this strategy has a significan drawback :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It depends heavily on the targeted point selection, this later may be not representative of all instances in the target class :  For instance, if the celebrity is known for a distinctive but uncommon style or if it&amp;rsquo;s unusual for such celebrities to attend such events, their attempt to copy him might not match what the security team usually expects from VIP guests.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Distribution based :&lt;/strong&gt; &lt;a name=&#34;subsection-13&#34;&gt;&lt;/a&gt;This new approach implemented in the paper we are analyzing , is based on Optimal Transport theory, and aims to alter the overall feature distribution ofa set of input images belonging to a specific class, to resemble another class&amp;rsquo;s distribution, reducing the gap between them in the &lt;strong&gt;feature space&lt;/strong&gt;. It is more sophisticated than the previous ones as it exploits the fundamental way neural networks process and classify images based on learned distributions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;This time, the group studies a wide variety of guests behaviors and appearances to craft a new, ambiguous look that doesn&amp;rsquo;t specifically mimic any single guest type, nor disguise blindly in a &amp;ldquo;VIP&amp;rdquo; style, but instead blends into the overall crowd, avoiding easy detection.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The main advantage of this approach is that it allows a better transferability between models, enhancing the performance in the blackbox configuration, as it is independant of the classifier&amp;rsquo;s decision boundary , and the choice of a specific target point. Furthermore it captures the useful characteristics (features) from an input in a more universal way.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;section-2&#34;&gt;Why do we need transferability ?&lt;/h2&gt;
&lt;p&gt;You surely noticed that we mentionned the transferability term many times in the last section, showing that is an essential property for designing such attacks, but why do we focus so much to make our patch transferable through many models? Well, it is like discovering a master key for many locks : It enables bad actors to compromise and confuse an AI system using a crafted patch they made without knowing anything about that system(architecture, training,&amp;hellip;).&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img src=&#34;./images/image_optimal_transport_patch/transferability_diagram.png&#34; alt=&#34;transferability_diagram&#34;&gt;
&lt;/p&gt;
&lt;p&gt;This ability to create a &amp;lsquo;one-size-fits-all&amp;rsquo; adversarial patch allows to challenge many models, making it more difficult to develop defense mechanisms, and fostering the development of more robust AI systems. Unfortunately, this important property, which confronts the real-world variability of target systems, whose specific architectures or training details are often unknown, was not achieved strongly by previously developped Adversarial attacks; it was studied only by some specialized Adversarial Patch Attacks models(GAP, LaVan, PS-GAN) and gave very modest rsults, being evaluated on dated, non state of the art models Other models (TTP, M3D, Inkawhich et al.) conducted some experiments to measure the transferability of ivisible adversarial attacks and gave promizing results, but they didn&amp;rsquo;t focus i their work on patch attacks transferability.&lt;/p&gt;
&lt;h2 id=&#34;section-3&#34;&gt;Diving into Optimal Transport theory&lt;/h2&gt;
&lt;p&gt;The method introduced in this paper represents a remarkable success, as it bridges the gap between transferability studies of invisible adversarial examples and adversarial patch attacks, and provides a trade-off between an efficient non complex patch designing approach, and an exceptional transferability among many advanced state-of-the-art models. The key reason for this success lies in the inherent capabilities of &lt;strong&gt;optimal transport&lt;/strong&gt; to measure the distance between two distributions. Particularly, the loss optimized in this method is relevant, as it can be used when the distributions do not overlap, and the theory behind it is intuitive. It is based mainly on the &lt;strong&gt;Wasserstain distance&lt;/strong&gt; defined as :&lt;/p&gt;
&lt;p&gt;$$W_{p}^p(\mu,\nu) = \inf_{\pi \in \Pi(\mu,\nu)} \int_{\mathbb{R}^d \times \mathbb{R}^d} ||x - y||^p d\pi(x, y)$$&lt;/p&gt;
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;MathJax Visualization Example&lt;/title&gt;
    &lt;script type=&#34;text/x-mathjax-config&#34;&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],
            displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],
            skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;]
        }
    });
    &lt;/script&gt;
    &lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;or its more computationnaly efficient Sliced version, which compares the two distributions by computing the expected Wasserstein distance between their one-dimensional linear projections :
$$SW_{p}^p(\mu,\nu) = \int_{S^{d-1}} W_{p}^p(\theta_{\#}^{*}\mu, \theta_{\#}^{*}\nu) d\sigma(\theta)$$&lt;/p&gt;
&lt;p&gt;
Where $\mu$ and $\nu$ are two propbability distributions on $\mathbb{R}^d$, $||.||$ the euclidean norm, $\pi$ is a transport plan between $\mu$ and $\nu$, and $ \theta_{\#}^{*} \mu $ and $ \theta_{\#}^{*} \nu $ the push-forward by $\theta^{*}(x)=&lt;\theta, x&gt;$ of $\mu$ and $\nu$ respectively.
&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img src=&#34;./images/image_optimal_transport_patch/Sliced_wasserstain.png&#34; alt=&#34;Sliced Wasserstain&#34;&gt;
  &lt;br&gt;
  &lt;em&gt;This image is taken and adapted from the &lt;a href=&#34;https://theses.hal.science/tel-03533097/document&#34;&gt;Sliced-Wasserstein distance for large-scale machine learning: theory, methodology and extensions&lt;/a&gt; paper.&lt;/em&gt;
&lt;/p&gt;
&lt;!-- $$SW_{p}(\mu,\nu) = \int_{S^{d-1}} W_{p}(\theta_{\#}\mu, \theta_{\#}\nu) d\sigma(\theta)$$--&gt;
&lt;p&gt;To delve more into the mathematical details, let us explore how Optimal Transport, specifically the Wasserstein distance, is employed to craft effective adversarial examples:
In the context of image classification, we consider the standard notation where a set of image-label pairs $(x_i, y_i)$ is drawn from a joint distribution of random variables $X$ and $Y$. The images $X$ are typically multi-dimensional arrays representing the height, width, and color channels of an image (e.g., a colored $256 \times 256$ pixel image would have $h = 256$, $w = 256$, and $c = 3$). Meanwhile, $Y$ is a set of discrete labels that classify these images (e.g., &amp;lsquo;cat&amp;rsquo;, &amp;lsquo;dog&amp;rsquo;, etc.). Within a given encoder-decoder neural network $F$, designed to predict these labels, the encoder function $f$ compresses the raw image data $X$ throughout each pooling layer into a feature space $S^{(l)}$, capturing essential patterns.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img src=&#34;./images/image_optimal_transport_patch/Optimal transport.png&#34; alt=&#34;Optimal Transport&#34;&gt;
&lt;/p&gt;
&lt;p&gt;The Wasserstein distance $W_p$, calculated between the distributions of these feature spaces, reflects how much &amp;ldquo;effort&amp;rdquo; it would take to transform the distribution of features from one class into another. In the case of the proposed method, crafting the patch consits of minimizing the transformation cost (distance)of the features distribution from a corrupted &amp;ldquo;true&amp;rdquo; class into a &amp;ldquo;target&amp;rdquo; adversarial class across multiple layers. This can be formulated as follows:&lt;/p&gt;
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;MathJax Visualization Example&lt;/title&gt;
    &lt;script type=&#34;text/x-mathjax-config&#34;&gt;
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],
            displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],
            skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;]
        }
    });
    &lt;/script&gt;
    &lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;
$$\delta^* = \arg \min_{\delta} \mathbb{E}_X \left[ \sum_{l \in \mathcal{L}} OT(\mu_{X_{\delta}}^{(l)}, \nu_y^{(l)}) \right]$$&lt;/p&gt;
&lt;p&gt;
Where $OT$ is the optimal transport distance (Wasserstein or Sliced Wasserstein), $\mu_{X_{\delta}}^{(l)}$ is the feature distribution of images with the patch and $\nu_y^{(l)}$ is the target feature distribution for the incorrect class.&lt;/p&gt;
&lt;p&gt;This can be further enhanced by adding a regularization term to ensure that the patches are effective under various conditions, and can be physically realisable. The problem becomes as follows :&lt;/p&gt;
&lt;p&gt;
$$\delta^* = \arg \min_{\delta} \mathbb{E}_{X, t\sim \tau, e\sim E} \left[ \sum_{l \in \mathcal{L}} OT(\mu_{A(\delta, X, e, t)}^{(l)}, \nu_y^{(l)}) + TV(\delta)\right]$$
where TV is the total variation loss discouraging high-frequency patterns.&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;
&lt;h2 id=&#34;section-4&#34;&gt;Experiments&lt;/h2&gt;
&lt;h3 id=&#34;experimental-setup&#34;&gt;Experimental setup &lt;a name=&#34;subsection-41&#34;&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To confirm the theoretical results and assumptions, several experiments were conducted under different conditions and settings. For the sake of simplicity, we will not delve into the exhaustive details of the experimental setup, procedures, and results. In summary:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The experiments aimed to evaluate the impact and transferability of the proposed adversarial patch - referred to as $(W_2^2)^{(1)} / (SW_2^2)_{500}^{(1)}$ - across a range of models.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$(W_2^2)^{(1)} / (SW_2^2)_{500}^{(1)}$ performance was benchmarked against other adversarial patch attack (APA) methods such as GAP, LaVAN, TNT, TTP, M3D, and others.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The source and target models chosen for this analysis were regrouped into six categories based on their architecture: CNNs-V1, CNNs-V2, ENet, CNext(ConvNext), DeiT, and Swin.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tested patches were randomly placed to the side of images, in order to avoid occluding the object of interest and replicate more closely the real world conditions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Targeted success rate (tSuc)&lt;/strong&gt; metric was used for evaluating transferability. It consists of the percentage of instances where the network, when presented with an image containing the adversarial patch, incorrectly classifies the image as the attacker&amp;rsquo;s intended target class, out of the total number of attempts.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;results-and-findings-&#34;&gt;Results and Findings : &lt;a name=&#34;subsection-42&#34;&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The experiments are structured into three main categories:&lt;/p&gt;
&lt;h4 id=&#34;digital-experiments-&#34;&gt;Digital experiments : &lt;a name=&#34;subsection-421&#34;&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;h5 id=&#34;simple-configuration-&#34;&gt;Simple configuration :&lt;/h5&gt;
&lt;p&gt;In this configuration, the patches efficacy was tested in a purely digital environment, using images from the ImageNet-1K dataset, which was used also for training. Patches were first designed to attack one of the source models, then tested on other target models to measure the attacking transferability. The table below summarizes for each APA method, the best transferring attack performance achieved :&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img src=&#34;./images/image_optimal_transport_patch/Digital_transferability.png&#34; alt=&#34;Digital Transferability&#34;&gt;
&lt;/p&gt;
&lt;p&gt;As expected through the novelty of $(W_2^2)^{(1)} / (SW_2^2)_{500}^{(1)}$ approach, it shows the highest transferability capacity(mean, min and max) and outperforms all the other methods. Additionaly, we can make the following observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Networks trained with older training recipes (CNNs-v1) seem more vulnerable to attacks, unlike tansformers and models trained with new training recipes (scheduler, augmenting training data like RandAug and Mixup, &amp;hellip;) which appear to be more robust.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For all APA methods, patches learned using Swin or CNext are more universal as they can transfer uniformly to multiple models.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In general, baseline methods tend to overfit and fail to generate patches that effectively transfer to complex architectures like CNext and Swin models, even if these patches are developed using the same category of models.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Methods based on feature space optimization, including L2 and the $(W_2^2)^{(1)} / (SW_2^2)_{500}^{(1)}$ approach, demonstrate improved transferability and are less likely to overfit.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;robustified-configuration-&#34;&gt;Robustified configuration :&lt;/h5&gt;
&lt;p&gt;In the second configuration of the digital experiments, the same procedures were reapplied. However this time, the methods learn on Swin, and transfer to a robustified version, by Local Gradients Smoothing (LGS) - a defense mechanism smoothing salient regions in images before passing them to the network - , of the six model categories.&lt;/p&gt;
&lt;p&gt;Similarly, $(W_2^2)^{(1)} / (SW_2^2)_{500}^{(1)}$ outperforms significantly all other methods as we can see in the following table :&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img src=&#34;./images/image_optimal_transport_patch/Digital_robustified.png&#34; alt=&#34;Digital robustified&#34;&gt;
&lt;/p&gt;
&lt;h4 id=&#34;hybrid-experiments&#34;&gt;Hybrid experiments: &lt;a name=&#34;subsection-422&#34;&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;In order to simulate real-world applications more closely, the hybrid experiments conducted within this section involved printing adversarial patches trained with Swin, placing them in physical environments, capturing the images, and then digitally analyzing the results, for simple, and robustified models.&lt;/p&gt;
&lt;p&gt;The table below shows the criticality of the $(W_2^2)^{(1)} / (SW_2^2)_{500}^{(1)}$ giving very large tSuc in comparison with the other methods, for all settings:&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
  &lt;img src=&#34;./images/image_optimal_transport_patch/Digital_robustified.png&#34; alt=&#34;Digital robustified&#34;&gt;
&lt;/p&gt;
&lt;h4 id=&#34;physical-experiments&#34;&gt;Physical experiments: &lt;a name=&#34;subsection-423&#34;&gt;&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;In this last experiments category, we get closer to the real world situations, by recording a video of some ImageNet-1K objects (banana, cup , keyboard) while moving a designed patch in the set. This aims to quantify the severity of each attack, for realistic scenarios (as the example provided above about the autonomous vehicule not detecting the stop sign while driving due to an adversarial patch designed without knowing the AI system at all).&lt;/p&gt;
&lt;p&gt;All APA methods failed to transfer properly on all architectures except for L2 with a modest tSuc(9.3%) and $(W_2^2)^{(1)} / (SW_2^2)_{500}^{(1)}$ that gave much better results (23.4% and 29.3%)&lt;/p&gt;
&lt;h2 id=&#34;section-5&#34;&gt;Reproducibility&lt;/h2&gt;
&lt;p&gt;In this section, we wanted to reproduce some of the experiments conducted in the paper to validate the results and the findings. However, by exploring the code provided with the paper, and analyzing the python files, we found that it is not well documented, and the structure is not very clear, which makes it difficult to understand and reproduce the complex experiments involving transferability evaluation. Furthermore, given that the paper is based on the ImageNet dataset, which is very large and requires a lot of computational resources, we were not able to run the experiments on our local machines, as we do not have access to a powerful GPU cluster. Consequently, we opted for the CIFAR-10 dataset, which is smaller and more manageable. Despite this adjustment, we still faced some issues Specifically, the model is built from scratch without an available pre-trained, and there are missing components, notably the function required to extract feature vectors from each layer of the target models. To address these challenges and make the reproduction process easier, we decided to develop the missing feature extraction function as an enhancement, and save the obtained results into files(in the same way it was done in the code), to be able to apply the optimal transport method and craft the adversarial patches later as perspectives&lt;/p&gt;
&lt;p&gt;Here are the code that we developed :&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torchvision.models&lt;/span&gt; &lt;span style=&#34;color:#00a8c8&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;models&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torchvision.transforms&lt;/span&gt; &lt;span style=&#34;color:#00a8c8&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;transforms&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torch.utils.data&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;DataLoader&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torchvision.datasets&lt;/span&gt; &lt;span style=&#34;color:#00a8c8&#34;&gt;as&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;datasets&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#00a8c8&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#75af00&#34;&gt;get_loader&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;dataset&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;str&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;split&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;str&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;batch_size&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;int&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;utils&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;DataLoader&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#d88200&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Return a DataLoader object for a given dataset and split.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#00a8c8&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;utils&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;DataLoader&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;get_dataset&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;dataset&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;split&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;),&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;batch_size&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;batch_size&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;shuffle&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#00a8c8&#34;&gt;True&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#00a8c8&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#75af00&#34;&gt;extract_features&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;data_loader&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;list_models&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#d88200&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;    Extracts features from each layer of the pre-trained models provided in the list_models
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;    by applying average pooling, and saves the extracted features into files.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#00a8c8&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;model_name&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;list_models&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#111&#34;&gt;model&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;models&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;__dict__&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;model_name&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;](&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;pretrained&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#00a8c8&#34;&gt;True&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#111&#34;&gt;model&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;eval&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#00a8c8&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;layer_name&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;layer&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;model&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;named_children&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#00a8c8&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;isinstance&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;layer&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;nn&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;Sequential&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#111&#34;&gt;layer_features&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;[]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#00a8c8&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;input&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;target&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;enumerate&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;data_loader&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#00a8c8&#34;&gt;with&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;no_grad&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        &lt;span style=&#34;color:#111&#34;&gt;output&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;layer&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;input&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        &lt;span style=&#34;color:#111&#34;&gt;output&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;nn&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;functional&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;adaptive_avg_pool2d&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;output&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        &lt;span style=&#34;color:#111&#34;&gt;output&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;output&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;view&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;output&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;),&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                        &lt;span style=&#34;color:#111&#34;&gt;layer_features&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;append&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;output&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#111&#34;&gt;layer_features&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;cat&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;layer_features&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#111&#34;&gt;torch&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;save&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;layer_features&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#d88200&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;&amp;#34;./data/CIFAR/all_images_feature/&lt;/span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;layer_name&lt;/span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;model_name&lt;/span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;.pt&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Apply the function extract_features to some targeted models&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#111&#34;&gt;list_models&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;&amp;#34;resnet18&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#d88200&#34;&gt;&amp;#34;vgg19&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#d88200&#34;&gt;&amp;#34;convnext_tiny&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#d88200&#34;&gt;&amp;#34;swin_t&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#111&#34;&gt;data_loader&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;get_loader&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#d88200&#34;&gt;&amp;#34;CIFAR10&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#d88200&#34;&gt;&amp;#34;train&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;batch_size&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#111&#34;&gt;extract_features&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;data_loader&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color:#111&#34;&gt;list_models&lt;/span&gt;&lt;span style=&#34;color:#111&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;section-6&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In conclusion, our exploration of the paper &lt;em&gt;&lt;strong&gt;OPTIMAL TRANSPORT BASED ADVERSARIAL PATCH TO LEVERAGE LARGE SCALE ATTACK TRANSFERABILITY&lt;/strong&gt;&lt;/em&gt;, revealed an innovative and promizing technique that uses Optimal Transport to make adversarial patches more effectively fool different models. This method, focusing on altering image feature distributions to match a target distribution from another class, has proven to be both theoretically sound and practically successful. It significantly outperforms current state of the art methods in creating patches that can be highly transferable between models and potentially very harmful, showing great promise for both advancements in the field and potential challenges in security applications.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://openreview.net/forum?id=nZP10evtkV&#34;&gt;OPTIMAL TRANSPORT BASED ADVERSARIAL PATCH TO LEVERAGE LARGE SCALE ATTACK TRANSFERABILITY&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://theses.hal.science/tel-03533097/document&#34;&gt;Sliced-Wasserstein distance for large-scale machine learning : theory, methodology and extensions&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1803.00567.pdf&#34;&gt;Computational Optimal Transport&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://openaccess.thecvf.com/content_CVPR_2019/papers/Inkawhich_Feature_Space_Perturbations_Yield_More_Transferable_Adversarial_Examples_CVPR_2019_paper.pdf&#34;&gt;Feature Space Perturbations Yield More Transferable Adversarial Examples&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      <author>Students from M2 Data Science IP Paris</author>
      <guid>http://localhost:1313/posts/optimal_transport_based_adversarial_patch/</guid>
      <pubDate>Sat, 03 Feb 2024 22:22:36 +0100</pubDate>
      <guid>http://localhost:1313/posts/optimal_transport_based_adversarial_patch/</guid>
      <description>&lt;style TYPE=&#34;text/css&#34;&gt;&#xD;&#xA;code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;    tex2jax: {&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;        displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;    }&#xD;&#xA;});&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script type=&#34;text/javascript&#34; src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;h1 id=&#34;authors&#34;&gt;Authors:&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Mohammed Jawhar&lt;/li&gt;&#xA;&lt;li&gt;Aymane Rahmoune&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;paper--optimal-transport-based-adversarial-based-patch-to-leverage-large-scale-attack-transferabilityhttpsopenreviewnetforumidnzp10evtkv&#34;&gt;Paper : &lt;a href=&#34;https://openreview.net/forum?id=nZP10evtkV&#34;&gt;Optimal Transport Based Adversarial Based Patch To Leverage Large Scale Attack Transferability&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;h1 id=&#34;table-of-contents-&#34;&gt;Table of contents :&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Understanding Adversarial Patch Attacks&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-11&#34;&gt;Decision boundary based&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-12&#34;&gt;Feature point based&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-13&#34;&gt;Distribution based&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Transferability&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Optimal Transport&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;Experiments&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-41&#34;&gt;Experimental Setup&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-42&#34;&gt;Results and Findings&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-421&#34;&gt;Digital Experiments&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-422&#34;&gt;Hybrid Experiments&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#subsection-423&#34;&gt;Physical Experiments&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;Reproducibility&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Imagine you&amp;rsquo;re showing a picture to a friend, asking them to guess who&amp;rsquo;s in it, then sticking a tiny, almost invisible sticker on that photo. For some reason, this sticker makes your friend completely unable to recognize who&amp;rsquo;s in the picture. This might sound like magic, but something similar can happen with Computer Vision models designed to capture an image content, either through a classification, a segmentation or even a generation task. These AI programs can be vulnerable to such tricks, that we call technically, Adversarial Patch Attacks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Statistical Minimax Rates Under Privacy</title>
      <link>http://localhost:1313/posts/statistical_minimax_rates_under_privacy/</link>
      <pubDate>Wed, 31 Jan 2024 17:22:02 +0100</pubDate>
      <guid>http://localhost:1313/posts/statistical_minimax_rates_under_privacy/</guid>
      <description>&lt;h1 style=&#34;font-size: 36px;&#34;&gt;Estimating Privacy in Data Science: A Comprehensive Guide&lt;/h1&gt;&#xD;&#xA;&lt;h1 style=&#34;font-size: 24px;&#34;&gt;Author: Antoine Klein &lt;a href=&#34;https://github.com/AntoineTSP&#34;&gt;Github Link&lt;/a&gt;&lt;/h1&gt;&#xD;&#xA;&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-0&#34;&gt;Incentives&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-1&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-2&#34;&gt;Definition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-3&#34;&gt;Theory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-4&#34;&gt;The case of multinomial estimation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-5&#34;&gt;The case of density estimation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-6&#34;&gt;Experiment&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-7&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#section-8&#34;&gt;Quizz&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;section-0&#34;&gt;Why do we care about privacy ?&lt;/h2&gt;&#xA;&lt;p&gt;Imagine, you&amp;rsquo;re quietly at home when the doorbell rings. You open the door and a government official appears: population census. Even though he shows you his official badge and you&amp;rsquo;d like to help him in the public interest, you find it hard to answer his questions as you go along. Indeed, the first questions about the date of your move are easy and public. On the other hand, when he asks about the number of children, marital status or your salary and what you do with it, you &lt;em&gt;struggle&lt;/em&gt;. Not because you don&amp;rsquo;t know the answer, but because you&amp;rsquo;re faced with an &lt;strong&gt;ethical dilemma&lt;/strong&gt;: transparency towards the state versus protection of personal data.&lt;br&gt;&#xA;$$\text{In short, transparency goes against your privacy. }$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Measuring the Transferability of Pre-trained Models: a link with Neural Collapse Distances on Target Datasets</title>
      <link>http://localhost:1313/posts/transferability/</link>
      <pubDate>Mon, 08 Jan 2024 11:26:03 +0100</pubDate>
      <guid>http://localhost:1313/posts/transferability/</guid>
      <description>&lt;script&#xD;&#xA;type=&#34;text/x-mathjax-config&#34;&gt;&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Config({&#xD;&#xA;&#xD;&#xA;    tex2jax: {&#xD;&#xA;&#xD;&#xA;        inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],&#xD;&#xA;&#xD;&#xA;        skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;] // removed &#39;code&#39; entry&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;MathJax.Hub.Queue(function() {&#xD;&#xA;&#xD;&#xA;    var all = MathJax.Hub.getAllJax(), i;&#xD;&#xA;&#xD;&#xA;    for(i = 0; i &lt; all.length; i += 1) {&#xD;&#xA;&#xD;&#xA;        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;&#xD;&#xA;&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;});&#xD;&#xA;&#xD;&#xA;&lt;/script&gt;&#xD;&#xA;&lt;script&#xD;&#xA;type=&#34;text/javascript&#34;&#xD;&#xA;src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;p&gt;&lt;strong&gt;Authors&lt;/strong&gt; : Marion Chadal and Julie Massé&lt;/p&gt;&#xA;&lt;p&gt;This blog post discusses the paper &amp;ldquo;How Far Pre-trained Models Are from Neural Collapse on the Target Dataset Informs their Transferability&amp;rdquo; &lt;a href=&#34;#ref1&#34;&gt;[1]&lt;/a&gt;. It provides an explanation of it so that you can understand the usefulness of measuring transferability, and a reproduction of the authors&amp;rsquo; experiment so that you can better visualize their methodology.&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;p&gt;Some additional informations about this course.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Florence d&amp;rsquo;Alché-Buc&lt;/strong&gt; is a full professor at Institut Polytechnique de Paris, Télécom Pari in Statistical Learning. She is the holder of the &amp;ldquo;Data Science and Artificial Intelligence for Digitalized Industry and Services&amp;rdquo; chair at Télécom Paris, and is mainly interested in learning from &lt;em&gt;complex&lt;/em&gt; data, in particular the supervised prediction of graphs, functions and spatio-temporal signals, exploiting the structure and geometry of these objects in regularization and cost functions. More recently, she has been working on the interpretability and robustness of predictive models. &lt;a href=&#34;https://perso.telecom-paristech.fr/fdalche/&#34;&gt;Link to personal webpage&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Articles</title>
      <link>http://localhost:1313/articles/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/articles/</guid>
      <description>&lt;p&gt;Hereafter you can find the list of articles proposed for this class and the link to the pdfs.&lt;/p&gt;&#xA;&lt;p&gt;Please add your name in the following &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1raZrD6JZQzjE0wmJbP4iM5-4yt9rAkJIFOqgj1q-JxU/edit?usp=sharing&#34;&gt;file&lt;/a&gt; to pick an article and enter your &lt;strong&gt;github username&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note 1&lt;/strong&gt;: this work can be done in teams (&lt;span style=&#34;text-decoration:underline&#34;&gt;maximum 3 students&lt;/span&gt;).&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note 2&lt;/strong&gt;: an article can only be chosen by &lt;span style=&#34;text-decoration:underline&#34;&gt;1 team&lt;/span&gt;.&lt;/p&gt;&#xA;&lt;hr/&gt;&#xD;&#xA;&lt;h2 id=&#34;tips-for-latex&#34;&gt;Tips for Latex&lt;/h2&gt;&#xA;&lt;p&gt;To activate latex writting you need to add this snippet of code (at the end or begining of the post)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tutorial</title>
      <link>http://localhost:1313/tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/tutorial/</guid>
      <description>&lt;p&gt;How to create and publish your blogpost ?&lt;/p&gt;&#xA;&lt;hr/&gt;&#xD;&#xA;&lt;p&gt;The blogpost builds upon &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; and &lt;a href=&#34;https://www.markdownguide.org/&#34;&gt;Markdown&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;For markdown you can easily find a cheat sheet &lt;a href=&#34;https://www.markdownguide.org/cheat-sheet/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;ol start=&#34;0&#34;&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Setup: you need to have a GitHub Account, a terminal and a text editor of your choice (e.g.VSCode, nano, gedit)&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Install Hugo on your laptop. Hugo is available for all operating systems. You can find the installation guide &lt;a href=&#34;https://gohugo.io/installation/&#34;&gt;here&lt;/a&gt;. Be careful, you need at least Hugo version 0.120 otherwise, this will not work!&#xA;To verify your version&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
